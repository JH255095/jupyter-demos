{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Financial Fraud Detection with Clearscape Analytics using SQL\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>Introduction</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "    In recent years we have seen a massive increase in Fraud attempts, making fraud detection imperative for Banking and Financial Institutions. Despite countless efforts and human supervision, hundreds of millions of dollars are lost due to fraud. Fraud can happen using various methods, i.e., stolen credit cards, misleading accounting, phishing emails, etc. Due to small cases in significant populations, fraud detection has become more and more challenging. \n",
    "    <br>\n",
    "    <br>\n",
    "    With ClearScape Analytics, data scientists can use their preferred language, tools and platform to develop models to identify this fraud. Even in large scale operations, users have the guarantee that Vantage can scale to their needs and reduce fraud.</p>\n",
    "    \n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Business Values</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Identification of financial fraud in multiple accounts</li>\n",
    "    <li>Pattern recognition of fraudulent versus normal transactions</li>\n",
    "    <li>Reduction of money lost due to recovering fraudulent charges</li>\n",
    "    <li>Improved customer satisfaction and reduction of customer churn</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Why Vantage?</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>To maximize the business value of advanced analytic techniques including Machine Learning and Artificial Intelligence, it is estimated that organizations must scale their model development and deployment pipelines to 100s or 1000s of times greater amounts of data, models, or both.\n",
    "    <br>\n",
    "    <br>\n",
    "    ClearScape Analytics provides powerful, flexible end-to-end data connectivity, feature engineering, model training, evaluation, and operational functions that can be deployed at scale as enterprise data assets; treating the products of ML and AI as first-class analytic processes in the enterprise.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>1. Connect to Vantage</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%connect local, hidewarnings=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Setup for execution of notebook. Begin running steps with Shift + Enter keys.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET query_band='DEMO=Financial_Fraud_Detection_InDB_SQL.ipynb;' UPDATE FOR SESSION;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Getting Data for This Demo</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. We have the option of either running the demo using foreign tables to access the data without using any storage on our environment or downloading the data to local storage, which may yield somewhat faster execution. However, we need to consider available storage. There are two statements in the following cell, and one is commented out. We may switch which mode we choose by changing the comment string.</p> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---call get_data('DEMO_GLM_Fraud_cloud');    -- takes about 1 minutes\n",
    "call get_data('DEMO_GLM_Fraud_local');    -- takes about 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Optional step â€“ We should execute the below step only if we want to see the status of databases/tables created and space used.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call space_report();  -- optional, takes about 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>3. Data Exploration</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We loaded the data from <a href = 'https://www.kaggle.com/code/georgepothur/4-financial-fraud-detection-xgboost/data'>https://www.kaggle.com/code/georgepothur/4-financial-fraud-detection-xgboost/data</a> into Vantage in a table named \"transaction_data\". We checked the data size and printed sample rows: 63k rows and 12 columns.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b><i>*Please scroll down to the end of the notebook for detailed column descriptions of the dataset.</i></b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Select count(*) from DEMO_GLM_Fraud.transaction_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Select Top 5 * from DEMO_GLM_Fraud.transaction_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In this simulated scenario, deceptive agents engage in transactions with the objective of taking control of customers' accounts, transferring funds to another account, and ultimately cashing out for profit.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>3.1 How many fraudulent transactions do we have in our dataset?</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT SUM(\n",
    "            CASE\n",
    "                WHEN isFraud=1 THEN 1 ELSE 0\n",
    "            END) AS \"Fraud Transactions\",\n",
    "        COUNT(*) AS \"Total Transactions\",\n",
    "        CAST(SUM(CAST(\n",
    "            CASE\n",
    "                WHEN isFraud=1 THEN 1 ELSE 0\n",
    "            END AS DECIMAL(7,4)))/\n",
    "            COUNT(*)  * 100 AS DECIMAL(4,2) format '9.99') || '%' AS \"Percent Fraud Transactions\"\n",
    "FROM DEMO_GLM_Fraud.transaction_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>3.2 How many transactions do we have group by transaction type?</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select \"type\", count(*) as typecnt from DEMO_GLM_Fraud.transaction_data group by 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%chart x=type, y=typecnt, mark=bar, title=\"No of Transactions per Transaction Type\", \n",
    "            width=700, height=300, gridx=false, gridy=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>3.3 How many fraudulent transactions do we have group by transaction type?</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \"type\" as \"Transaction Type\",\n",
    "    SUM(\n",
    "    CASE\n",
    "        WHEN isFraud=1 THEN 1 ELSE 0\n",
    "    END) AS \"Fraud Transactions by Type\"\n",
    "FROM DEMO_GLM_Fraud.transaction_data\n",
    "    GROUP BY 1 HAVING \"Fraud Transactions by Type\" > 0 ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%chart x=\"Transaction Type\", y=\"Fraud Transactions by Type\", mark=bar, title=\"No of Fraud Transactions per Transaction Type\", \n",
    "            width=500, height=400, gridx=false, gridy=false, labelx=\"Transaction Type\", \n",
    "            labely= \"Count of Fraud Transactions by Type\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>From the above result, we can see that out of the 92 fraud transactions, 47 are from transaction type \"TRANSFER\" and 45 are from \"CASH_OUT\".</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>3.4 What percentage of fraudulent transactions do we have where transaction amount is equal to old balance in the origin account?</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This might be the case where the fraudster emptied the account of the victim.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT SUM(\n",
    "    CASE\n",
    "        WHEN isFraud=1 AND amount=oldbalanceOrig THEN 1 ELSE 0\n",
    "    END) AS \"Cleanout Fraud Transactions\",\n",
    "        CAST(SUM(CAST(\n",
    "    CASE\n",
    "        WHEN isFraud=1 AND amount=oldbalanceOrig THEN 1 ELSE 0\n",
    "    END AS DECIMAL(7,4)))/\n",
    "    SUM(\n",
    "    CASE\n",
    "        WHEN isFraud=1 THEN 1 ELSE 0\n",
    "    END) * 100 AS DECIMAL(5,2)) || '%' AS \"Percent Cleanout Fraud Transactions\"\n",
    "FROM DEMO_GLM_Fraud.transaction_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>From the above result, we can see that out of 92 Fraud transactions, the amount involved in 90 fraud transactions was equal to the total balance in the account. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Below are some insights about the dataset:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>We have 92 fraud transactions, which account for 0.14% of the dataset.</li>\n",
    "    <li>Out of these 92 fraud transactions, 47 are of type TRANSFER, and 45 are of type CASH_OUT.</li>\n",
    "    <li>Approximately 97.83% of our fraud transactions have a transaction amount equal to oldbalanceOrig, indicating account cleanout.</li>\n",
    "    <li>About 71.74% of our fraud transactions have the recipient's old balance as zero.</li>\n",
    "    <li>The isFlaggedFraud indicator is correct only two times among our 92 fraud transactions.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>3.5 Univariate statistics</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <code>TD_UnivariateStatistics</code> funtion computes the count, mean, std, min, percentiles, and max for numeric columns.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT TOP 5 *\n",
    "    FROM TD_UnivariateStatistics(\n",
    "    ON \"DEMO_GLM_Fraud\".\"transaction_data\" AS InputTable\n",
    "    USING\n",
    "    TargetColumns('step','amount','oldbalanceOrig','newbalanceOrig','oldbalanceDest',\n",
    "                                'newbalanceDest','isFraud','isFlaggedFraud','txn_id')\n",
    "    Stats('COUNT','MAXIMUM','MEAN','MINIMUM','PERCENTILES','STANDARD DEVIATION')\n",
    "    Centiles(25,50,75)\n",
    "    ) AS t;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>3.6 Checking for Null Values</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The TD_ColumnSummary() function can be used to take a quick look at the columns, their datatypes, and summary of NULLs/non-NULLs for a given table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * FROM TD_ColumnSummary(\n",
    "    ON \"DEMO_GLM_Fraud\".\"transaction_data\" AS InputTable\n",
    "    USING\n",
    "    TargetColumns('[:]')\n",
    ") as t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>3.7 Checking for Outliers</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The TD_OutlierFilterFit() function calculates the lower percentile, upper percentile, count of rows and median for all the \"target_columns\" provided by the user. These metrics for each column help the function OutlierTransform() detect outliers in data.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT TOP 5 *\n",
    "    FROM TD_OutlierFilterFit(\n",
    "    ON \"DEMO_GLM_Fraud\".\"transaction_data\" AS InputTable\n",
    "    OUT TABLE OutputTable(\"OutlierFilterFit_out\")\n",
    "    USING\n",
    "    TargetColumns('amount','newbalanceOrig','oldbalanceDest','newbalanceDest','oldbalanceOrig')\n",
    "    ) AS sqlmr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE MULTISET TABLE OutlierFiltertransform_out AS (\n",
    "    SELECT *\n",
    "        FROM TD_OutlierFilterTransform(\n",
    "        ON \"DEMO_GLM_Fraud\".\"transaction_data\" AS InputTable \n",
    "        ON \"OutlierFilterFit_out\" AS FitTable DIMENSION\n",
    "    ) AS sqlmr )WITH DATA;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select Top 5 * from OutlierFiltertransform_out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT totalrows as \"Total Rows\",\n",
    "    rowsafteroutliers as \"Row after Outliers\",\n",
    "    totalrows-rowsafteroutliers AS \"Number of Outliers\"\n",
    "    FROM\n",
    "    (\n",
    "    SELECT COUNT(*) AS totalrows\n",
    "        FROM \"DEMO_GLM_Fraud\".\"transaction_data\") a,\n",
    "        (\n",
    "    SELECT COUNT(*) AS rowsafteroutliers\n",
    "        FROM \"OutlierFiltertransform_out\")b;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT TOP 5 *\n",
    "    FROM \n",
    "    (\n",
    "    SELECT *\n",
    "        FROM \"DEMO_GLM_Fraud\".\"transaction_data\" MINUS\n",
    "    SELECT *\n",
    "        FROM \"OutlierFiltertransform_out\") a;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>4. Data Preparation</b>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial'><b>We'll perform the following steps:</b></p>\n",
    "<ul style='font-size:16px;font-family:Arial'>\n",
    "    <li>We will one-hot encode the categorical \"type\" column.</li>\n",
    "    <li>We will perform feature scaling using ScaleFit and ScaleTransform on numerical columns.</li>\n",
    "    <li>We will split the data into training and testing datasets (80:20 split).</li>\n",
    "</ul>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial'>We perform feature scaling during data pre-processing to handle highly varying magnitudes, values, or units. If feature scaling is not done, then a machine learning algorithm tends to weigh greater values higher and consider smaller values as lower ones, regardless of the unit of the values.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>4.1 Drop redundant columns</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We don't need nameDest, nameOrigin, and isFlaggedFraud for model training as they do not impact the outcome. We have txn_id to uniquely identify each transaction.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE MULTISET TABLE txn_data AS (\n",
    "    SELECT step,\n",
    "        \"type\",\n",
    "        amount,\n",
    "        oldbalanceOrig,\n",
    "        newbalanceOrig,\n",
    "        oldbalanceDest,\n",
    "        newbalanceDest,\n",
    "        isFraud,\n",
    "        txn_id\n",
    "        FROM \"DEMO_GLM_Fraud\".\"transaction_data\")WITH DATA PRIMARY INDEX(txn_id);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select Top 5 * from txn_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>4.2 One-hot encoding</b></p>\n",
    "<p style='font-size:16px;font-family:Arial'>\n",
    "Here, we are one-hot encoding the \"type\" column. We find one-hot encoding necessary in many cases to represent categorical variables as binary values, enable numerical processing, ensure feature independence, handle non-numeric data, and improve the performance and interpretability of our machine learning models.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE MULTISET TABLE onehotencodingfittable AS (\n",
    "    SELECT *\n",
    "        FROM TD_OneHotEncodingFit (\n",
    "        ON txn_data AS InputTable\n",
    "        USING\n",
    "        TargetColumn ('\"type\"')\n",
    "        IsInputDense ('true')\n",
    "        CategoryCounts(5)\n",
    "        Approach('Auto')    \n",
    ") AS dt) WITH DATA;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE MULTISET TABLE clean_data AS (\n",
    "    SELECT *\n",
    "        FROM TD_OneHotEncodingTransform (\n",
    "        ON txn_data AS InputTable\n",
    "        ON onehotencodingfittable AS FitTable DIMENSION\n",
    "        USING\n",
    "        IsInputDense('True')\n",
    ") AS dt ) WITH DATA PRIMARY INDEX(txn_id);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select Top 5 * from clean_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above output shows that we have transformed the data into a transfromed dataset.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>5. Create training and testing datasets in Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We'll create two datasets for training and testing in the ratio of 80:20.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE MULTISET TABLE traintest_data AS (\n",
    "    SELECT *\n",
    "        FROM TD_TrainTestSplit(\n",
    "        ON clean_data AS InputTable\n",
    "        USING\n",
    "        IDColumn('txn_id')\n",
    "        seed(25)\n",
    "        trainSize(0.8)\n",
    "        testSize(0.2)\n",
    ") AS sqlmr) WITH DATA PRIMARY INDEX(txn_id);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE MULTISET TABLE clean_data_train AS (\n",
    "    SELECT step,\n",
    "        type_0,\n",
    "        type_1,\n",
    "        type_2,\n",
    "        type_3,\n",
    "        type_4,\n",
    "        type_other,\n",
    "        amount,\n",
    "        oldbalanceOrig,\n",
    "        newbalanceOrig,\n",
    "        oldbalanceDest,\n",
    "        newbalanceDest,\n",
    "        isFraud,\n",
    "        txn_id\n",
    "        FROM traintest_data\n",
    "        WHERE TD_IsTrainRow = 1)WITH DATA PRIMARY INDEX(txn_id);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE MULTISET TABLE clean_data_test AS (\n",
    "    SELECT step,\n",
    "        type_0,\n",
    "        type_1,\n",
    "        type_2,\n",
    "        type_3,\n",
    "        type_4,\n",
    "        type_other,\n",
    "        amount,\n",
    "        oldbalanceOrig,\n",
    "        newbalanceOrig,\n",
    "        oldbalanceDest,\n",
    "        newbalanceDest,\n",
    "        isFraud,\n",
    "        txn_id\n",
    "        FROM traintest_data\n",
    "        WHERE TD_IsTrainRow = 0)WITH DATA PRIMARY INDEX(txn_id);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above output shows that we have split into train and test dataset.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>6. In-Database XGBoost model training</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The TD_XGBoost() function, also known as eXtreme Gradient Boosting, is an implementation of the gradient boosted decision tree algorithm designed for speed and performance. It has recently been dominating applied machine learning.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In gradient boosting, each iteration fits a model to the residuals (errors) of the previous iteration to correct the errors made by existing models. The predicted residual is multiplied by this learning rate and then added to the previous prediction. Models are added sequentially until no further improvements can be made. It is called gradient boosting because it uses a gradient descent algorithm to minimize the loss when adding new models.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE MULTISET TABLE xgb_model AS (\n",
    "    SELECT *\n",
    "        FROM TD_XGBoost(\n",
    "        ON \"clean_data_train\" AS \"input\"\n",
    "        PARTITION BY ANY\n",
    "        USING\n",
    "        InputColumns('amount','newbalanceOrig','oldbalanceDest','newbalanceDest','oldbalanceOrig',\n",
    "                                            'type_0','type_1','type_2','type_3','type_4')\n",
    "        ResponseColumn('isFraud')\n",
    "        MaxDepth(7)\n",
    "        Seed(42)\n",
    "        ModelType('Classification')\n",
    "        RegularizationLambda(120.0)\n",
    "        ShrinkageFactor(0.1)\n",
    ") AS sqlmr )WITH DATA;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The function output is a trained XGBoost model, and we can input it to the XGBoostPredict() function for prediction.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>7. In-Database XGBoost model scoring</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The TD_XGBoostPredict() function runs the predictive algorithm based on the model generated by TD_XGBoost(). The TD_XGBoost() function, also known as eXtreme Gradient Boosting, performs classification or regression analysis on datasets.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "When using the function, we should provide only numeric features. We need to convert the categorical features to numeric values before prediction.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE MULTISET TABLE XGBPredict AS (\n",
    "    SELECT *\n",
    "        FROM TD_XGBoostPredict(\n",
    "        ON \"clean_data_test\" AS inputtable\n",
    "        PARTITION BY ANY \n",
    "        ON \"xgb_model\" AS ModelTable\n",
    "        DIMENSION\n",
    "        ORDER BY \"task_index\", \"tree_num\", \"iter\", \"tree_order\"\n",
    "        USING\n",
    "        IdColumn('txn_id')\n",
    "        Accumulate('isFraud')\n",
    "        OutputProb('True')\n",
    "        ModelType('Classification')\n",
    "        Responses('0','1')\n",
    ") AS sqlmr )WITH DATA;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Select Top 5 * from XGBPredict;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The output above shows our prob_1, i.e., the transaction is fraud, and prob_0, i.e., the transaction is not a fraud. We use these probabilities in our prediction column to assign a class label.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT *\n",
    "    FROM TD_ClassificationEvaluator(\n",
    "    ON XGBPredict AS InputTable\n",
    "    PARTITION BY ANY\n",
    "    OUT TABLE OutputTable(classeval_out)\n",
    "    USING\n",
    "    ObservationColumn('isFraud')\n",
    "    PredictionColumn('Prediction')\n",
    "    Labels('0','1')\n",
    "    ) AS sqlmr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select * from classeval_out;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>8. Visualize the results (ROC curve and AUC)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We create the ROC curve, which is a graph between TPR (True Positive Rate) and FPR (False Positive Rate). We use the area under the ROC curve as a metric to evaluate how well our model can distinguish between positive and negative classes. A higher AUC indicates better performance in distinguishing between the positive and negative categories. We generally consider an AUC above 0.75 as decent.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT *\n",
    "    FROM TD_ROC(\n",
    "    ON XGBPredict AS InputTable PARTITION BY ANY\n",
    "    OUT TABLE OutputTable(roc_out)\n",
    "    USING\n",
    "    ProbabilityColumn('\"Prob_1\"')\n",
    "    ObservationColumn('isFraud')\n",
    "    NumThresholds(300)\n",
    "    ) AS sqlmr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select * from roc_out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%chart x=fpr, y=tpr, mark=line, title=\"ROC\", \n",
    "            width=500, height=400, gridx=false, gridy=false, labelx=\"False Positive Rate\", \n",
    "            labely= \"True Positive Rate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Looking at the above ROC Curve, we can confidently say that our model has performed well on testing data. The AUC value is above 0.75 and resonates with our understanding that the model is performing well.</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Conclusion</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this demonstration, we have illustrated a simplified - but complete - overview of how we can implement a typical machine learning workflow completely inside the database using Vantage. This allows us to leverage Vantage's operational scale, power, and stability.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>9. Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We need to clean up our work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP TABLE OutlierFilterFit_out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP TABLE OutlierFiltertransform_out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP TABLE txn_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP TABLE onehotencodingfittable;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP TABLE xgb_model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP TABLE XGBPredict;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP TABLE classeval_out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP TABLE roc_out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP TABLE traintest_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP TABLE clean_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP TABLE clean_data_train;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP TABLE clean_data_test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We will use the following code to clean up tables and databases created for this demonstration.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call remove_data('demo_glm_fraud');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<b style = 'font-size:20px;font-family:Arial'>Required Materials</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Letâ€™s look at the elements we have available for reference for this notebook:</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Filters:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><b>Industry:</b> Finance</li>\n",
    "    <li><b>Functionality:</b> Machine Learning</li>\n",
    "    <li><b>Use Case:</b> Fraud Detection</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Related Resources:</b></p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><a href='https://www.teradata.com/Blogs/Fraud-Busting-AI'>Fraud-Busting-AI</a></li>\n",
    "    <li><a href='https://www.teradata.com/Industries/Financial-Services'>Financial Services</a></li>\n",
    "    <li><a href='https://www.teradata.com/Resources/Datasheets/Move-from-Detection-to-Prevention-and-Outsmart-Fraudsters'>Move from Detection to Prevention and Outsmart Tech-Savvy Fraudsters</a></li>\n",
    "</ul>\n",
    "\n",
    "<b style = 'font-size:20px;font-family:Arial'>Dataset:</b>\n",
    "\n",
    "- `txn_id`: transaction id\n",
    "- `step`: maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (31 days simulation).\n",
    "- `type`: CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER\n",
    "- `amount`: amount of the transaction in local currency\n",
    "- `nameOrig`: customer who started the transaction\n",
    "- `oldbalanceOrig`: customer's balance before the transaction\n",
    "- `newbalanceOrig`: customer's balance after the transaction\n",
    "- `nameDest`: customer who is the recipient of the transaction\n",
    "- `oldbalanceDest`: recipient's balance before the transaction\n",
    "- `newbalanceDest`: recipient's balance after the transaction\n",
    "- `isFraud`: identifies a fraudulent transaction (1) and non fraudulent (0)\n",
    "- `isFlaggedFraud`: flags illegal attempts to transfer more than 200,000 in a single transaction\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Uses a dataset and feature discovery methods outlined here: <a href = 'https://www.kaggle.com/georgepothur/4-financial-fraud-detection-xgboost/notebook'>https://www.kaggle.com/georgepothur/4-financial-fraud-detection-xgboost/notebook</a></li>\n",
    "    <li>Teradata Clearscape Analytics reference: <a href = 'https://docs.teradata.com/search/all?query=Analyze+Your+Data+with+ClearScape+Analytics%25E2%2584%25A2&content-lang=en-US'>here</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analyticsâ„¢</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright Â© Teradata Corporation - 2024,2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Teradata SQL",
   "language": "Teradata SQL",
   "name": "teradatasql"
  },
  "language_info": {
   "codemirror_mode": "Teradata SQL",
   "file_extension": ".tdrs",
   "mimetype": "application/vnd.teradata.resultset",
   "name": "Teradata SQL",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "16.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
