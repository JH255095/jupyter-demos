{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38bc532d-c78c-4c89-b191-242da0733f39",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Teradata Enterprise Vector Store : Vectorizing PDFs\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff71661-19b4-423a-867a-7c815b064c81",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Introduction:</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the Chat with documentation system using Generative AI demo, the combination of <b>RAG, Langchain, and LLM models</b> allows users to ask queries in layman's terms, retrieve relevant information from the Vector store, and generate accurate and concise answers based on the retrieved data. This integration of retrieval-based and generative-based approaches provides a powerful tool for extracting knowledge from structured sources and delivering user-friendly responses.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this demo we will build Chatbot using Panel (for chat UI), LangChain, a powerful library for working with LLMs like GPT-3.5, GPT-4, Bloom, etc. and JumpStart in ClearScape notebooks, a system is built where users can ask business questions in natural English and receive answers with data drawn from the relevant databases.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following diagram illustrates the architecture.</p>\n",
    "\n",
    "<center><img src=\"images/rag1.png\" alt=\"architecture\"  width=1200 height=1000/></center>\n",
    "\n",
    "\n",
    "<br>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Before going any farther, let's get a better understanding of RAG, LangChain, and LLM.</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'><b><li> Retrieval-Augmented Generation (RAG):</li></b></ol>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> &emsp;  &emsp;RAG is a framework that combines the strengths of retrieval-based and generative-based approaches in question-answering systems.It utilizes both a retrieval model and a generative model to generate high-quality answers to user queries. The retrieval model is responsible for retrieving relevant information from a knowledge source, such as a database or documents. The generative model then takes the retrieved information as input and generates concise and accurate answers in natural language.</p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>A typical RAG (Retrieval-and-Generation) application has two main components:</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Indexing:</b> a pipeline for ingesting data from a source and indexing it. This usually happens offline. The indexing process involves several steps, including loading the data, splitting it into smaller chunks, and storing and indexing the splits. This is often done using a VectorStore and Embeddings model.</p>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Retrieval and generation:</b> the actual RAG chain, which takes the user query at run time and retrieves the relevant data from the index, then passes that to the model. The retrieval process involves searching the index for the most relevant data based on the user query, and then passing that data to the model for generation.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The most common full sequence from raw data to answer looks like:</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Indexing</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Load:</b> Load: First we need to load our data. We'll use <code>PyPDFLoader</code> for this.</li>\n",
    "    <li><b>Split:</b> Text splitters break large Documents into smaller chunks. This is useful both for indexing data and for passing it in to a model, since large chunks are harder to search over and won't in a model's finite context window. Here, our pdf document will be splits into pages.</li>\n",
    "    <li><b>Store:</b> We need somewhere to store and index our splits, so that they can later be searched over. This is often done using a VectorStore and Embeddings model</li>\n",
    "    </ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following diagram illustrates the architecture of load, split and store.</p>\n",
    "\n",
    "<center><img src=\"images/rag_load_store.png\" alt=\"rag indexing architecture\"  width=800 height=600/></center>\n",
    "<center>image source: <a href=\"https://python.langchain.com/docs/use_cases/question_answering/\">langchain.com</a></center>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Retrieval and generation</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Retrieval:</b> During runtime, the user inputs a query. We first generate embeddings for it, which are then passed to the Vantage in the db_function <b>TD_VectorDistance</b> to retrieve similar documents as context. This context is then fed into the LLM model.</li>\n",
    "    <li><b>Generation:</b> Finally, the model generates an answer based on the retrieved data. The answer is then presented to the user.</li>\n",
    "    </ul>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following diagram illustrates the architecture of retrieval and generation.</p>\n",
    "<center><img src=\"images/rag_retrieval_generation_td.png\" alt=\"retrieval generation architecture\" width=800 height=600/></center>\n",
    "<center>image source: <a href=\"https://python.langchain.com/docs/use_cases/question_answering/\">langchain.com</a></center>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C' start=\"2\"><b><li> Langchain:</li></b></ol>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> &emsp;  &emsp; LangChain is a framework that facilitates the integration and chaining of large language models with other tools and sources to build more sophisticated AI applications. LangChain does not serve its own LLMs; instead, it provides a standard way of communicating with a variety of LLMs, including those from OpenAI and HuggingFace. LangChain accelerates the development of AI applications with building blocks. We learn the leverage the following building blocks in this notebook:</p>\n",
    " \n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li> <b> LLMs</b> – LangChain's <code>llm</code> class is designed to provide a standard interface for all LLM it supports.   </li>\n",
    "    <li> <b> PromptTemplate</b>  - LangChain’s <code>PromptTemplate</code> class are predefined structures for generating prompts for LLM’s. They can be reused across different LLM's.</li>\n",
    "    <li> <b> Chains</b> – When we build complex AI applications, we may need to combine multiple calls to LLM’s and to other components  LangChain’s <code>chain</code> class allows us to link calls to LLM’s and components. The most common type of chaining in any LLM application is combining a prompt template with an LLM and optionally an output parser. </li>\n",
    "</ol>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C' start=\"3\"><b><li> LLM Models (Large Language Models):</li></b></ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> &emsp;  &emsp; LLM models refer to the large-scale language models that are trained on vast amounts of text data.\n",
    "These models, such as GPT-3 (Generative Pre-trained Transformer 3),  GPT-3.5, GPT-4, HuggingFace BLOOM, LLaMA, Google's FLAN-T5, etc. are capable of generating human-like text responses. LLM models have been pre-trained on diverse sources of text data, enabling them to learn patterns, grammar, and context from a wide range of topics. They can be fine-tuned for specific tasks, such as question-answering, natural language understanding, and text generation.\n",
    "LLM models have achieved impressive results in various natural language processing tasks and are widely used in AI applications for generating human-like text responses.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca49b9d-df0b-400a-acf8-0252ab8a2618",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233c'><b>Steps in the analysis:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Configuring the environment</li>\n",
    "    <li>Connect to Vantage</li>\n",
    "    <li>Data Exploration</li>\n",
    "    <li>Generate the embeddings</li>\n",
    "    <li>Load the existing embeddings to DB</li>\n",
    "    <li>Calculate the VectorDistance using Teradata Vantage in-DB function</li>\n",
    "    <li>LLM</li>\n",
    "    <li>Chat with documents</li>\n",
    "    <li>Cleanup</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833b5bf-74af-42be-8543-3782e1da95dc",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>1. Configuring the environment</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94f1e8-489b-4084-80c6-c9cff1ef6ee8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>1.1 Install the required libraries</b></p>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note:</b>The installation of the required libraries will take approximately <b>4 to 5 minutes</b> for the first-time installation. However, if the libraries are already installed, the execution will complete within 5 seconds.</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6027a7-888d-441f-abc7-a6ea1c45f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4466b8-c2fc-4a81-8baf-541997ad1ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy==1.22.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b160ce-5ace-4116-86b6-394d6502553b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>The above statements will install the required libraries to run this demo. Be sure to restart the kernel after executing the above lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "    </div>\n",
    "    \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>To ensure that the Chatbot interface reflects the latest changes, please reload the page by clicking the 'Reload' button or pressing F5 on your keyboard for <b>first-time only</b> This will update the notebook with the latest modifications, and you'll be able to interact with the Chatbot using the new libraries.</i></p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61067c88-2e9a-4c92-985b-34dc4ab74a13",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>1.2 Import the required libraries</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea50a4aa-1211-44fc-8166-317c35253207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.0' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/opt/conda/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/jovyan/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import timeit\n",
    "\n",
    "# teradata lib\n",
    "from teradataml import *\n",
    "\n",
    "# helper functions\n",
    "from utils.sql_helper_func import *\n",
    "from utils.tdapiclient_helper_func import *\n",
    "from utils.transcripts_helper_func import *\n",
    "\n",
    "# LLM\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import boto3 \n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.schema import Document\n",
    "import sqlite3\n",
    "import json\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "display.max_rows = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e11368d-2efb-4906-8e28-d50f0bca6429",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i>The code above will download the necessary models to generate the embeddings required to run this demo. The initial download may take approximately 50-60 seconds minutes if you are running this demo for the first time in this environment. However, subsequent runs will be much faster since the models will already be available locally.</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59718f8-7af4-4d1a-abc7-a860eb7cbae3",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>2. Connect to Vantage and OpenAI</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83770df6-b923-4cc4-a839-de55c62b32ae",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>2.1 Connect to Vantage</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "164cfc91-93ed-45b9-98ba-73b91a50c28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing setup ...\n",
      "Setup complete\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter password:  ·········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Logon successful\n",
      "Connected as: teradatasql://demo_user:xxxxx@host.docker.internal/dbc\n",
      "Engine(teradatasql://demo_user:***@host.docker.internal)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TeradataCursor uRowsHandle=13 bClosed=False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)\n",
    "execute_sql('''SET query_band='DEMO= Chat_with_docs_VantageDB_GenAI_Python.ipynb;' UPDATE FOR SESSION;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fdd83d-8dbb-4301-b967-eafe2658bf5c",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>2.2 Confirmation for functions</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Before starting let us confirm that the required functions are installed.</p>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f08f5be-0504-4c2c-9c09-44edd6dfc2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions are installed, please continue.\n"
     ]
    }
   ],
   "source": [
    "df_check= DataFrame.from_query('''select count(*) as cnt from dbc.tablesV where databasename = 'ivsm';''')\n",
    "if df_check.get_values()[0][0] >= 10:\n",
    "    print('Functions are installed, please continue.')\n",
    "else:\n",
    "    print('Functions are not installed, please go to Instalization notebook before proceeding further')\n",
    "    display(Markdown(\"[Initialization Notebook](./Initialization_and_Model_Load.ipynb)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f3fe2-ed63-4838-bb19-4c0d0157453d",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>3. Data Exploration Getting Data for This Demo</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Chat with documentation demo aims to demonstrate how users can interact with documents such as insurance policy wordings, invoices, and other similar documents through a conversational interface.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Traveller Easy Single Trip - International insurance policy is a comprehensive travel insurance plan that provides cover for a wide range of risks, including medical expenses, trip cancellation, loss of luggage, and personal accident. The policy is designed to be affordable and flexible, and it can be purchased online or over the phone.<p/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6b94e0-bb25-46a2-a6a9-5eedaa1d39a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database DEMO_SLM_RAG_local exists\n",
      "Database DEMO_ComplaintAnalysis_local exists\n"
     ]
    }
   ],
   "source": [
    "%run -i ../run_procedure.py \"call get_data('DEMO_SLM_RAG_local');\"\n",
    "\n",
    "# for call NL to SQL\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_ComplaintAnalysis_local');\"     \n",
    " # Takes about 2 minutes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a762f2e5-fd9a-4306-8dd9-f635996a7ddb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optional step – We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f2ba64d-11f6-4fb5-a52f-51cb6f379955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have:  #databases=6 #tables=13 #views=11  You have used 468.5 MB of 30,678.3 MB available - 1.5%  ... Space Usage OK\n",
      " \n",
      "   Database Name                  #tables  #views     Avail MB      Used MB\n",
      "   demo_user                            8       5  27,657.7 MB     259.0 MB \n",
      "   DEMO_ComplaintAnalysis               0       4       0.0 MB       0.0 MB \n",
      "   DEMO_ComplaintAnalysis_db            4       0   2,442.2 MB       9.3 MB \n",
      "   DEMO_HyperModel                      0       1       0.0 MB       0.0 MB \n",
      "   DEMO_SLM_RAG                         0       1       0.0 MB       0.0 MB \n",
      "   DEMO_SLM_RAG_db                      1       0       6.2 MB       4.5 MB \n",
      "   ivsm                                 0       0     572.2 MB     195.7 MB \n"
     ]
    }
   ],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1626b5-1693-4683-a275-5aa80c862f8d",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<a id='section4'></a>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>4. Read source data. </b>\n",
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>4.1 Run the data loader </b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cfd968-aaac-45cd-8f3c-35fac1218981",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The source data from <a href=\"https://axa-com-my.cdn.axa-contento-118412.eu/axa-com-my/3d2f84a5-42b9-459b-911a-710546df0633_Policy+wording+-+SmartTraveller+Easy+Single+Trip+-+International+%280820%29.pdf\">AXA</a> is loaded in Teradata Vantage as Vector Database.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now, let's use <code>PyMuPDFLoader</code> library to read the pdf document and split it into pages.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>For Audio files <code>openai/whisper-small</code> open source audio model we have used to extract the transcripts and split it into pages.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2386198-83cb-4c17-9eb2-597807b58720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_id(df, id_column='id', start_id=1000):\n",
    "    if df.empty or df[id_column].max() < start_id:\n",
    "        return start_id\n",
    "    else:\n",
    "        return df[id_column].max() + 1\n",
    "\n",
    "def get_splitter():\n",
    "    # split the page content\n",
    "    return RecursiveCharacterTextSplitter(\n",
    "        chunk_size=200,\n",
    "        chunk_overlap=30,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    \n",
    "def read_document_content(raw_data_df, pages, file_name):\n",
    "    docs = [p.page_content for p in pages]\n",
    "    docs = get_splitter().create_documents(docs)\n",
    "    \n",
    "    texts_data = []\n",
    "    for t in docs:\n",
    "        texts_data.append(t.page_content)\n",
    "\n",
    "    # generate the dataframe\n",
    "    temp_df = pd.DataFrame(data=texts_data, columns=[\"txt\"])\n",
    "    next_id = get_next_id(raw_data_df)\n",
    "    temp_df[\"id\"] = range(next_id, len(temp_df.index) + next_id)\n",
    "    temp_df['txt'] = texts_data\n",
    "    temp_df['file_name'] = file_name                       \n",
    "    \n",
    "    # Concatenate the new DataFrame with the existing one\n",
    "    return pd.concat([raw_data_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f658e404-6618-4379-b915-3f8e1b2b04fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main raw df                \n",
    "raw_data_df = pd.DataFrame({col: pd.Series(dtype=dt) for col, dt in columns.items()})\n",
    "\n",
    "def read_data_files(directory_path, raw_data_df):\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        if \".ipynb_checkpoints\" in root:\n",
    "            continue\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            if file_name.lower().endswith('.mp3'):\n",
    "                print(f\"MP3 File: {file_name}\")\n",
    "                transcripts = process_audio(file_path)\n",
    "                texts = get_splitter().create_documents([transcripts])\n",
    "                raw_data_df = read_document_content(raw_data_df, texts, file_name)\n",
    "            elif file_name.lower().endswith('.pdf'):\n",
    "                print(f\"PDF File: {file_name}\")\n",
    "                pages = PyMuPDFLoader(file_path).load_and_split()\n",
    "                print('total pages: ', len(pages))\n",
    "                raw_data_df = read_document_content(raw_data_df, pages, file_name)\n",
    "            elif file_name.lower().endswith('.txt'):\n",
    "                print(f\"TXT File: {file_name}\")\n",
    "                with open(file_path, 'r') as file:\n",
    "                    text_content = file.read()\n",
    "                    texts = get_splitter().create_documents([text_content])\n",
    "                    raw_data_df = read_document_content(raw_data_df, texts, file_name)\n",
    "            else:\n",
    "                print(f\"Skipping: {file_name}\")\n",
    "                \n",
    "    return raw_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35ee55-230f-498e-b52a-b55f93c3f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = './data'\n",
    "final_raw_data_df = read_data_files(directory_path, raw_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0aa71d-457d-448a-ad11-da18ed77dd94",
   "metadata": {},
   "source": [
    "<p style='font-size:16px;font-family:Arial;color:#00233C'>In the above cell, we will read all the pages of the PDF file and split them into pages. To process further, we will split them into semantic character splits to maintain the context of sentences.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaf7b0e-4907-40cd-be0e-f828dfe53f52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy docs to vantage\n",
    "copy_to_sql(final_raw_data_df, table_name=\"docs_data\", primary_index=\"id\", if_exists=\"replace\")\n",
    "\n",
    "tdf_docs = DataFrame(\"docs_data\")\n",
    "print(\"Data information: \\n\", tdf_docs.shape)\n",
    "tdf_docs.sort(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c83ad71-58cb-4338-88bc-0d529f25cec0",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To generate the embeddings, we will call the <b>generate_embeddings_tdapiclient()</b> function. This function will takes the Teradata DataFrame as input generate the embeddings and returns embeddings dataframe. Once the embeddings are generated, we will pass them to the <b>VectorDistance()</b> function later on to get the recommendations.</p>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note: The embedding generation step is estimated to take approximately 2 to 4 minutes to complete. If you prefer to skip this step and proceed to the next section, please click  <a href=\"#section50\">here</a> to skip.</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a442943-d13f-4c0f-a2a5-4d22294d4a55",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Please be patient:</b> Generating embeddings for 1500+ document contents may take up to 2 to 4 minutes. It is depends on number of APMS in the database. Since the volume of data is large and the machine is small, going through the below code could take up to 4 minutes. </i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a95d65-8866-4423-9a52-2dec04c63ab4",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>5. Generate embeddings from the chunks.</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will create prompts for different questions that can be answered from the document. Below are some sample questions that can be asked.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca8f97-c763-4969-980c-cdd1ff0b0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"\"\"replace view v_pdf_tokenized_for_embeddings  as (\n",
    "    select\n",
    "        id,\n",
    "        txt,\n",
    "        file_name,\n",
    "        IDS as input_ids,\n",
    "        attention_mask\n",
    "    from ivsm.tokenizer_encode(\n",
    "        on (select * from docs_data)\n",
    "        on (select model as tokenizer from embeddings_tokenizers where model_id = 'bge-small-en-v1.5') DIMENSION\n",
    "        USING\n",
    "            ColumnsToPreserve('id', 'txt', 'file_name')\n",
    "            OutputFields('IDS', 'ATTENTION_MASK')\n",
    "            MaxLength(1024)\n",
    "            PadToMaxLength('True')\n",
    "            TokenDataType('INT64')\n",
    "    ) a\n",
    ");\"\"\"\n",
    "\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('View Created')\n",
    "except:\n",
    "    print(error)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97934bc5-cf41-4ce7-be7f-2e06dc5ceb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry=\"\"\"replace view pdf_embeddings as (\n",
    "    select \n",
    "            *\n",
    "    from ivsm.IVSM_score(\n",
    "            on v_pdf_tokenized_for_embeddings  -- table with data to be scored\n",
    "            on (select * from embeddings_models where model_id = 'bge-small-en-v1.5') dimension\n",
    "            using\n",
    "                ColumnsToPreserve('id', 'txt', 'file_name') -- columns to be copied from input table\n",
    "                ModelType('ONNX') -- model format\n",
    "                BinaryInputFields('input_ids', 'attention_mask') -- enables binary input vector\n",
    "                BinaryOutputFields('sentence_embedding')\n",
    "                Caching('inquery') -- tun on model caching within the query\n",
    "        ) a \n",
    ");\"\"\"\n",
    "\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('View Created')\n",
    "except:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d565b-5898-4859-b28e-0a2779c2cee9",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>5.1 Do you want to generate the embeddings?</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Generating embeddings will take around <b>35-40 minutes.</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have already generated embeddings for the pdf and stored them in <b>Vantage</b> table.</p>\n",
    " \n",
    "<center><img src=\"images/decision_emb_gen_2.svg\" alt=\"embeddings_decision\"  width=300 height=400/></center>\n",
    " \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note: If you would like to skip the embedding generation step to save the time and move quickly to next step, please enter \"No\" in the next prompt.</b></i></p>\n",
    "</div>\n",
    " \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To save time, you can move to the already generated embeddings section. However, if you would like to see how we generate the embeddings, or if you need to generate the embeddings for a different dataset, then continue to the following section.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cb446a-daac-4bc7-81f5-7a8559da2f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# Request user's input\n",
    "generate = input(\"Do you want to generate embeddings? ('yes'/'no'): \")\n",
    "\n",
    "# Check the user's input\n",
    "if generate.lower() == 'yes':\n",
    "    print(\"\\nGreat! We'll start by generating embeddings.\")\n",
    "\n",
    "    print(\"\\nGenerating embeddings and Saving to the database, please wait...\")\n",
    "    # start = time.time()\n",
    "    qry=\"\"\"create table pdf_embeddings_store as (\n",
    "    select \n",
    "    *\n",
    "    from ivsm.vector_to_columns(\n",
    "            on pdf_embeddings\n",
    "            using\n",
    "                ColumnsToPreserve('id', 'txt') \n",
    "                VectorDataType('FLOAT32')\n",
    "                VectorLength(384)\n",
    "                OutputColumnPrefix('emb_')\n",
    "                InputColumnName('sentence_embedding')\n",
    "        ) a ) with data ;\"\"\"\n",
    "\n",
    "    try:\n",
    "        execute_sql(qry)\n",
    "        # end = time.time()\n",
    "        print('Table Created')\n",
    "        # print(end-start)\n",
    "        \n",
    "    except:\n",
    "        db_drop_table('pdf_embeddings_store')\n",
    "        execute_sql(qry)\n",
    "        # end = time.time()\n",
    "        print('Table Created')\n",
    "        # print(end-start)\n",
    "\n",
    "\n",
    "    print(\"\\nEmbeddings generated and saved successfully!\")\n",
    "\n",
    "elif generate.lower() == 'no':\n",
    "    print(\"\\nLoading embeddings from the Vantage table\")\n",
    "    # Save them to SQL\n",
    "    df_emb = DataFrame(in_schema(\"DEMO_SLM_RAG\",\"Pdf_Embedding_Data\"))\n",
    "    copy_to_sql(\n",
    "        df = df_emb,\n",
    "        table_name = 'pdf_embeddings_store',\n",
    "        if_exists = 'replace'\n",
    "    )\n",
    "\n",
    "    print(\"\\nEmbeddings loaded and saved successfully!\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nInvalid input. Please enter 'yes' or 'no' to proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae7c12f-d304-4b4d-b497-1c3319f09bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_embeddings_store = DataFrame('pdf_embeddings_store')\n",
    "tdf_embeddings_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf215b71-2758-406a-b962-b1bf5651ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_embeddings_store.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb61754-527e-467b-86f1-4ec6f98e0d45",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>6. Insert Prompts into a Table</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0664918-7abc-4c30-8fc3-7af415475475",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will create the required table and than we will insert different values for the prompts.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d9aac-60e9-4422-aafb-205e3d00bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = '''CREATE MULTISET TABLE pdf_topics_of_interest(\n",
    "      txt VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "      id INT) NO PRIMARY INDEX''' ;\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "except:\n",
    "    db_drop_table('pdf_topics_of_interest')\n",
    "    execute_sql(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59b19d1-80cc-4397-aee5-d43fb1fa5656",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will create prompts for different questions that can be answered from the document. Below are some sample questions that can be asked.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c761d88d-813f-40ae-b8b2-a9500bbb04ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"Does this policy cover  Loss of or Damage to the Insured’s Articles?\",\n",
    "\"What is the reimbursement limit per Baggage?\",\n",
    "\"What is the sum insured amount in the case Accidental Death in domestic and international for adult as well as child?\",\n",
    "\"What documents are required for Rental Car Excess?\",\n",
    "\"Where can I submit my complaints or feedback?\",\n",
    "\"What is the bank tenure of customer 789456123?\"]\n",
    "\n",
    "for idx, prompt in enumerate(prompts, start=1):\n",
    "    execute_sql(f'''INSERT into pdf_topics_of_interest values ('{prompt}', {idx});''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd2227-0019-4ff4-b9f0-d62e7e1e1086",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>7. Generate Embeddings from the Prompts</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will create embeddings for the prompts which we have inserted into the table above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d39984-914e-4434-b01e-6e9c65619994",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"\"\"replace view v_pdf_topics_tokenized_for_embeddings as (\n",
    "    select\n",
    "        id,\n",
    "        txt,\n",
    "        IDS as input_ids,\n",
    "        attention_mask\n",
    "    from ivsm.tokenizer_encode(\n",
    "        on (select * from pdf_topics_of_interest)\n",
    "        on (select model as tokenizer from embeddings_tokenizers where model_id = 'bge-small-en-v1.5') DIMENSION\n",
    "        USING\n",
    "            ColumnsToPreserve('id', 'txt')\n",
    "            OutputFields('IDS', 'ATTENTION_MASK')\n",
    "            MaxLength(1024)\n",
    "            PadToMaxLength('True')\n",
    "            TokenDataType('INT64')\n",
    "    ) a\n",
    ");\"\"\"\n",
    "\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('View Created')\n",
    "except:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40baa623-35ac-4dac-8e3f-a9d752df60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry=\"\"\"replace view pdf_topics_embeddings as (\n",
    "    select \n",
    "            *\n",
    "    from ivsm.IVSM_score(\n",
    "            on v_pdf_topics_tokenized_for_embeddings  -- table with data to be scored\n",
    "            on (select * from embeddings_models where model_id = 'bge-small-en-v1.5') dimension\n",
    "            using\n",
    "                ColumnsToPreserve('id', 'txt') -- columns to be copied from input table\n",
    "                ModelType('ONNX') -- model format\n",
    "                BinaryInputFields('input_ids', 'attention_mask') -- enables binary input vectors\n",
    "                BinaryOutputFields('sentence_embedding')\n",
    "                Caching('inquery') -- tun on model caching within the query\n",
    "        ) a \n",
    ");\"\"\"\n",
    "\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('View Created')\n",
    "except:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa11a2-ffcc-4ed8-a6b3-c4e160713b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"\"\"create table pdf_topics_embeddings_store as (\n",
    "    select \n",
    "            *\n",
    "    from ivsm.vector_to_columns(\n",
    "            on pdf_topics_embeddings\n",
    "            using\n",
    "                ColumnsToPreserve('id', 'txt') \n",
    "                VectorDataType('FLOAT32')\n",
    "                VectorLength(384)\n",
    "                OutputColumnPrefix('emb_')\n",
    "                InputColumnName('sentence_embedding')\n",
    "        ) a \n",
    ") with data;\"\"\"\n",
    "\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('Table Created')\n",
    "except:\n",
    "    db_drop_table('pdf_topics_embeddings_store')\n",
    "    execute_sql(qry)\n",
    "    print('Table Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4026aa09-8275-44c7-ad55-8a9b4040631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_topics_embeddings_store = DataFrame('pdf_topics_embeddings_store')\n",
    "tdf_topics_embeddings_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2098357a-9a91-4df6-adef-b8fc79003a64",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>8. Find top 10 matching chunks</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will find the top 10 chunks that match the queries using the <b>TD_VectorDistance</b>. The TD_VectorDistance function accepts a table of target vectors and a table of reference vectors and returns a table that contains the distance between target-reference pairs. The function computes the distance between the target pair and the reference pair from the same table. We must have the same column order in the TargetFeatureColumns argument and the RefFeatureColumns argument. The function ignores the feature values during distance computation if the value is either NULL, NAN, or INF.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe2b4f-2fce-4a28-9352-00ee495f6f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry=\"\"\"create multiset table pdf_semantic_search_results\n",
    "as (\n",
    "SELECT \n",
    "    dt.target_id,\n",
    "    dt.reference_id,\n",
    "    e_tgt.txt as target_txt,\n",
    "    e_ref.txt as reference_txt,\n",
    "    (1.0 - dt.distance) as similarity \n",
    "FROM\n",
    "    TD_VECTORDISTANCE (\n",
    "        ON pdf_topics_embeddings_store AS TargetTable\n",
    "        ON pdf_embeddings_store AS ReferenceTable DIMENSION\n",
    "        USING\n",
    "            TargetIDColumn('id')\n",
    "            TargetFeatureColumns('[emb_0:emb_383]')\n",
    "            RefIDColumn('id')\n",
    "            RefFeatureColumns('[emb_0:emb_383]')\n",
    "            DistanceMeasure('cosine')\n",
    "            topk(5)\n",
    "    ) AS dt\n",
    "JOIN pdf_topics_embeddings_store e_tgt on e_tgt.id = dt.target_id\n",
    "JOIN pdf_embeddings_store e_ref on e_ref.id = dt.reference_id\n",
    ") with data;\"\"\"\n",
    "\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('Table Created')\n",
    "except:\n",
    "    db_drop_table('pdf_semantic_search_results')\n",
    "    execute_sql(qry)\n",
    "    print('Table Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfaa087-7176-4e4d-b1d0-07e4575fb345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b302a70-0e2f-4a02-9719-357ae5619f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_semantic_search_results = DataFrame('pdf_semantic_search_results').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91641389-04be-4200-846b-78f65858c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_semantic_search_results.sort_values([\"target_id\", \"similarity\"]).iloc[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b04db-fe87-4ed2-8ca4-21c8311ce990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_search_context(target_id):\n",
    "    return str.join('\\n',pdf_semantic_search_results.loc[pdf_semantic_search_results['target_id'] ==target_id][['reference_txt']].reference_txt.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096e48c5-803d-492b-b4f1-d5799345102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similarity_search_context(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853abd90-5f61-4f02-be41-bf1fef65b325",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>10. Configuring AWS CLI and Initialize Bedrock Model</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following cell will prompt us for the following information:</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "<li><b>aws_access_key_id</b>: Enter your AWS access key ID</li>\n",
    "<li><b>aws_secret_access_key</b>: Enter your AWS secret access key</li>\n",
    "<li><b>region name</b>: Enter the AWS region you want to configure (e.g., us-east-1)</li>\n",
    "<ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a51778f-ad16-4939-b1ea-8db5a92e3102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_aws():\n",
    "    print(\"configure the AWS CLI\")\n",
    "    # enter the access_key/secret_key\n",
    "    access_key = getpass.getpass(\"aws_access_key_id \")\n",
    "    secret_key = getpass.getpass(\"aws_secret_access_key \")\n",
    "    region_name = getpass.getpass(\"region name\")\n",
    "\n",
    "    #set to the env\n",
    "    !aws configure set aws_access_key_id {access_key}\n",
    "    !aws configure set aws_secret_access_key {secret_key}\n",
    "    !aws configure set default.region {region_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd8eda1-662c-4f4f-b082-c6fcf6810647",
   "metadata": {},
   "outputs": [],
   "source": [
    "does_access_key_exists = !aws configure get aws_access_key_id\n",
    "\n",
    "if len(does_access_key_exists) == 0:\n",
    "    configure_aws()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8fb8a1-bd99-4336-a12c-9cfb00dbf784",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws configure list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac8578e-c837-4ec9-90fb-85430be57698",
   "metadata": {},
   "source": [
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Initialize the Bedrock Model</b>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "<li>The code below initializes a Boto3 client for the “bedrock-runtime” service.</li>\n",
    "<li>The get_llm() function creates a Bedrock language model with specific configuration options.</li>\n",
    "<li>The model can be used for natural language generation tasks.</li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42119db6-2785-4a83-94a9-11fbfc83a668",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In case you want to check answer for some other question please enter the question again <a href='#rule'>here</a> and run the following steps again.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26f6369-811f-45a3-8bbb-28e853695e7c",
   "metadata": {},
   "source": [
    "### SQL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5842c-e7f1-4333-820a-2c7430110276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "#  Create the vantage SQLAlchemy engine\n",
    "database = \"DEMO_ComplaintAnalysis_db\"\n",
    "db = SQLDatabase(\n",
    "    eng,\n",
    "    schema=database,\n",
    "    include_tables=[\"Customer_360_Details\"],\n",
    ")\n",
    "\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b7e93-a952-4794-9e78-e292c54eafd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_d = {\n",
    "    \"Customer_360_Details\": complaints_data.columns,\n",
    "}\n",
    "\n",
    "\n",
    "def get_db_schema():\n",
    "    table_dicts = []\n",
    "    for k in main_d:\n",
    "        table_dicts.append(\n",
    "            {\n",
    "                # \"database_name\": database,\n",
    "                \"table_name\": k,\n",
    "                \"column_names\": main_d[k],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    database_schema_string = \"\\n\".join(\n",
    "        [\n",
    "            f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "            for table in table_dicts\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return database_schema_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae81a2fc-990e-4f44-be64-f6a198f27329",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_schema = get_db_schema()\n",
    "print(database_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74cb32a-3b4a-402c-9924-ee2eaaac6049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21787594-d460-4768-8d44-eeb1cda129ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f06e9-9fb2-492d-a679-c3081062d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate    \n",
    "\n",
    "prefix = \"\"\"You are an helpful and expert TeradataSQL database admin. TeradataSQL shares many similarities to SQL, with a few key differences.\n",
    "Given an input question, first create a syntactically correct TeradataSQL query to run, then look at the results of the query and return the answer.\n",
    "\n",
    "IMPORTANT: Unless the user specifies an exact number of rows they wish to obtain, you must always limit your query to at most {top_k} results by using \"SELECT TOP {top_k}\".\n",
    "\n",
    "The following keywords do not exist in TeradataSQL: \n",
    "1. LIMIT \n",
    "2. FETCH\n",
    "3. FIRST\n",
    "Instead of LIMIT or FETCH, use the TOP keyword. The TOP keyword should immediately follow a \"SELECT\" statement.\n",
    "For example, to select the top 3 results, use \"SELECT TOP 3 FROM <table_name>\"\n",
    "Enclose all value identifiers in quotes to prevent errors from restricted keywords. Append an underscore to all alias keywords (e.g., AS count_).\n",
    "Always use double quotation marks (\" \") for column names in SQL queries to avoid syntax errors.\n",
    "NOT make any DML statements (INSERT, UPDATE, DELETE, DROP, etc.) to the database. \n",
    "If the question does not seem related to the database, just return \"I don't know\" as the answer\n",
    "\n",
    "IMPORTANT: Use default database as 'DEMO_ComplaintAnalysis'\n",
    "\n",
    "IMPORTANT:Only use the following Column names: \\n\n",
    "\"\"\" + database_schema + \"\"\"\n",
    "\n",
    "You have access to the following tools:\"\"\"\n",
    "\n",
    "format_instructions = \"\"\"You must always the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Don't forget to prefix your final answer with the string, \"Final Answer:\"!\"\"\"\n",
    "\n",
    "suffix = \"\"\"Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\"\"\"\n",
    "\n",
    "custom_prompt = ChatPromptTemplate.from_template(\"\\n\\n\".join([\n",
    "    prefix,\n",
    "    \"{tools}\",\n",
    "    format_instructions,\n",
    "    suffix,\n",
    "]))\n",
    "\n",
    "\n",
    "agent=create_sql_agent(\n",
    "    llm=llm,\n",
    "    db=db,\n",
    "    agent_type=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    prompt=custom_prompt,\n",
    "    max_iterations=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd02df2-f217-4b9b-8751-b5471a9e6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     question = \"What is the similarity score between target_id 1 and reference_id 1031?\"\n",
    "#     response = agent.invoke(question)\n",
    "#     if isinstance(response, dict) and 'output' in response:\n",
    "#         answer = response['output']\n",
    "#     else:\n",
    "#         answer = \"No valid response received.\"\n",
    "#     print(f\"Query: {question}\\nResponse: {answer}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34565dc-9b25-4582-a9db-7cce2bc0da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ad464-7dee-4805-aeda-69ac20874133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_classifier():\n",
    "    query_classifier_prompt = PromptTemplate(\n",
    "        input_variables=[\"query\"],\n",
    "        template=\"\"\"Classify if the following query requires:\n",
    "            1. SQL database (if it's asking about structured data like Customer_360_Details, Customer Identifier, Name, City, State, Customer Type, Product Holdings, Total Deposit Balance, Total Credit Balance, Total Investments AUM, Customer Profitability,\n",
    "             Customer Lifetime Value, Bank Tenure, Affluence Segment, Digital Banking Segment, Branch Banking Segment.)\n",
    "            2. Vector database (if it's asking about document content, general knowledge, customer complaints)\n",
    "            3. Both (if it needs to combine information from structured data and documents)\n",
    "            \n",
    "            Query: {query}\n",
    "            \n",
    "            Return only one word: SQL, VECTOR, or BOTH\n",
    "            \"\"\",\n",
    "    )\n",
    "    return LLMChain(llm=llm, prompt=query_classifier_prompt)\n",
    "\n",
    "\n",
    "def _query_vector_store(query: str) -> str:\n",
    "    \"\"\"Query the vector store and return relevant content\"\"\"\n",
    "    context = get_similarity_search_context\n",
    "\n",
    "    response_prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"query\"],\n",
    "        template=\"\"\"Using the following context, answer the question:\n",
    "\n",
    "        Context: {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Answer:\"\"\",\n",
    "    )\n",
    "\n",
    "    response_chain = LLMChain(llm=llm, prompt=response_prompt)\n",
    "    response = response_chain.run({\"context\": context, \"query\": query})\n",
    "    return response\n",
    "\n",
    "\n",
    "def _combine_responses(sql_response: str, vector_response: str, query: str) -> str:\n",
    "    \"\"\"Combine responses from SQL and vector stores\"\"\"\n",
    "    combination_prompt = PromptTemplate(\n",
    "        input_variables=[\"sql_response\", \"vector_response\", \"query\"],\n",
    "        template=\"\"\"Combine the following information to provide a complete answer:\n",
    "\n",
    "        SQL Database Info: {sql_response}\n",
    "        Document Info: {vector_response}\n",
    "        Original Question: {query}\n",
    "\n",
    "        Combined Answer:\"\"\",\n",
    "    )\n",
    "\n",
    "    combination_chain = LLMChain(llm=llm, prompt=combination_prompt)\n",
    "    combined_response = combination_chain.run(\n",
    "        {\n",
    "            \"sql_response\": sql_response,\n",
    "            \"vector_response\": vector_response,\n",
    "            \"query\": query,\n",
    "        }\n",
    "    )\n",
    "    return combined_response\n",
    "\n",
    "\n",
    "def process_query(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Process user query and return appropriate response\n",
    "    \"\"\"\n",
    "    # Classify query type\n",
    "    query_type = _get_classifier().run(query).strip().upper()\n",
    "    print(\"**** query_type: **** \", query_type)\n",
    "    if query_type == \"SQL\":\n",
    "        return agent.invoke(query)\n",
    "\n",
    "    elif query_type == \"VECTOR\":\n",
    "        return _query_vector_store(query)\n",
    "\n",
    "    elif query_type == \"BOTH\":\n",
    "        sql_response = agent.invoke(query)\n",
    "        vector_response = _query_vector_store(query)\n",
    "        return _combine_responses(sql_response, vector_response, query)\n",
    "\n",
    "    else:\n",
    "        return \"Unable to classify query type. Please rephrase your question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd66156-7779-4e2a-9c43-f219de65c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_query(\"Does this policy cover  Loss of or Damage to the Insured's Articles?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ffcd2c-feff-484a-99f8-d77238d30ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_data = DataFrame(in_schema('DEMO_ComplaintAnalysis', 'Customer_360_Details'))\n",
    "complaints_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ebdbf9-719d-4885-8075-5a2ee8be6690",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_query(\"What is the bank tenure of customer 789456123?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c131eb-d042-4d9f-a020-ec6f98e16c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_query(\"What is the total deposit balance of customer 987654321 and What documents are required for Rental Car Excess?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8df1cb-0cf6-48ba-8a3e-94e5987b1fb3",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<a id=\"rule\"></a>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>9. Create Context and Prompt for LLM</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will create context and prepare instructions and prompt to the LLM.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c0bdf-8e06-42ce-8011-16a1b85df968",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = input(\"Please enter your question \")\n",
    "\n",
    "process_query(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f95c14-3753-4c01-b718-3c04b852b430",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Below are some options available.</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'> prompt = [\"Does this policy cover  Loss of or Damage to the Insured's Articles?\"]</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'> prompt = [\"What is the reimbursement limit per Baggage?\"]</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'> prompt = [\"What is the sum insured amount in the case Accidental Death in domestic and international for adult as well as child?\"]</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'> prompt = [\"What documents are required for Rental Car Excess?\"]</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'> prompt = [\"Where can I submit my complaints or feedback?\"]</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a50194-c223-45f6-87d9-a3c8b6448673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50b8b817-c0ff-42b3-a651-c8268ac40942",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>12. Cleanup</b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>12.1 Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8c3d7-3772-419f-b462-3e8ab8cc5268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in db_list_tables()['TableName'].tolist():\n",
    "    try:\n",
    "        db_drop_table(table_name=table, schema_name=\"demo_user\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d26a8a-23a9-4324-8379-1e6b426ce6e5",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'> <b>12.2 Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the following code to clean up tables and databases created for this demonstration.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e4803-5b5f-464b-8004-15df96c99d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_ComplaintAnalysis');\"        # Takes 5 seconds\n",
    "%run -i ../run_procedure.py \"call remove_data('DEMO_SLM_RAG');\"   # Takes 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30521be8-1d18-48b2-a857-d5377ac0e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5463848-592f-4321-b852-287e133872dd",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
