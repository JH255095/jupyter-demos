{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f2f3523-c5f5-42c1-8e78-eb8a818fd487",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial;color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Telco Churn using Enterprise Feature Store and AutoML in Vantage\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcccb19d-7b60-4ab3-a0e4-d939e3351e54",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;'><b>AutoML Approach</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Teradataml <b>Auto</b>mated <b>M</b>achine <b>L</b>earning (AutoML) provides functionality to automate the end-to-end machine learning flow. AutoML takes data scientist productivity to next-level by automatically train high-quality models specific to their business needs. AutoML represents a method for streamlining the entire process of machine learning pipeline in automated way. It encompasses various distinct phases of the machine learning pipeline, including feature exploration, features engineering, data preparation, model selection, model training with hyperparameters tuning, and model evaluation. By automating these tasks, AutoML eliminates the need for manual intervention by trained data scientists and reduces the prerequisite knowledge required for beginners. This accessibility allows individuals of varying expertise levels to effortlessly use AutoML to create machine learning models in an automated fashion.\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Key Features of Teradata AutoML approach:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li>Helps users determine the most optimal model automatically.</li>\n",
    "    <li>Increases ease of use in model building</li>\n",
    "    <li>Supports various problem types, including Regression, Binary Classification, and Multiclass Classification.</li>\n",
    "    <li>Provides five different models for training: GLM, SVM, Decision Forest, XGBoost, and KNN.</li>\n",
    "    <li>Flexibility to select specific models out of the available models.</li>\n",
    "    <li>All five phases are automated and can be customized based on user input.</li>\n",
    "    <li>Generates model leaderboard and leader for a given dataset.</li>\n",
    "    <li>Allows prediction on validation dataset and on user passed data on the leader board</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Below are the different phases of AutoML:</p>\n",
    "</p>\n",
    "<center><img src=\"images/AutoML_phases.png\" alt=\"efs\" width=800 height=1200 style='border: 4px solid #404040; padding-right:15px; border-radius: 10px;'></center>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>Why Vantage?</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>To maximize the business value of advanced analytic techniques including Machine Learning and Artificial Intelligence, it is estimated that organizations must scale their model development and deployment pipelines to 100s or 1000s of times greater amounts of data, models, or both.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>There are several reasons why EFS naturally fits to Teradata Vantage:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>Utilizes Teradata Vantage with its powerful Analytical Library and SQL Engine.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>Primary Index enables efficient single-row access for online feature use.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>Single platform for both online and offline feature stores.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>Macros reduce parsing overhead from API access.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>R and Python code execution within SQL Engine.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>Bi-temporal querying capability.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>Scalable MPP power for feature computation.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>Industry-specific Logical Data Model as a feature source.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>Connectivity to Object Storage via NOS for feature data sourcing.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>Query Grid facilitates access to multiple data sources.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>Close-to-real-time feature delivery using Query Services and Teradata Intelligent Memory.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>Workload management prioritizes tasks effectively.</li></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The unique massively-parallel architecture of Teradata Vantage allows users to prepare data, train, evaluate, and deploy models at unprecedented scale.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab6f86e-5e58-435a-a8f2-a4eb3176aa3d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>1. Connect to Vantage, Import python packages and explore the dataset</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe80ce62-d761-4ffe-b171-93b036739e92",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d409c76-27ef-4940-98c0-c541aa9cb1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# '%%capture' suppresses the display of installation steps of the following packages\n",
    "!pip install --upgrade teradataml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0df2d7-7b1c-413c-bd59-5f87035f9a90",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Note: </b><i>Please execute the above pip install to get the latest version of the required library. Be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb9b4e-8690-4de6-ab49-211f6413cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Teradata libraries\n",
    "from teradataml import *\n",
    "display.max_rows = 5\n",
    "\n",
    "# Data manipulation and visualization libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcca830-84d7-452b-9a4a-21853933afd4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f0bcc-56ad-4513-bdab-abae45f09a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdaaddd-c5f8-4699-9c54-72a3dcc711f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=EE_Telco_Customer_Churn_AutoML_Approach.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80e18e4-d009-4d88-8340-72636ca8f0dd",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>2. Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We have provided data for this demo on cloud storage. We have the option of either running the demo using foreign tables to access the data without using any storage on our environment or downloading the data to local storage, which may yield somewhat faster execution. However, we need to consider available storage. There are two statements in the following cell, and one is commented out. We may switch which mode we choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9ef52-74ad-4c33-b978-0d5d8a68f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_Telco_cloud');\"\n",
    " # takes about 30 seconds, estimated space: 0 MB\n",
    "%run -i ../../run_procedure.py \"call get_data('DEMO_Telco_local');\" \n",
    "# takes about 1 minute 30 seconds, estimated space: 4 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe942be5-f0b5-4ed4-b8a5-58d4821f3f3a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Optional step – We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf32774-d606-48a8-9d04-0f3e87f2d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3f055-339c-4371-bb2f-913e934f287d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>3. Data Exploration</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ccb32-a2f7-4728-b255-8ef4839688c7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let us start by creating a \"Virtual DataFrame\" that points directly to the dataset in Vantage. We then begin our analysis by checking the shape of the DataFrame and examining the data types of all its columns.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c7dab3-3da3-47e1-b9e6-2c99cd3b09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = DataFrame(in_schema(\"DEMO_Telco\", \"Customer_Churn\"))\n",
    "tdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f4111-4fa1-4991-af17-d06e51da6b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the data: \", tdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc760ba-8bb2-4065-a9cd-9d9668b68ee7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> As we can see from above result our dataset has 7043 rows with 21 columns.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe49ae0-c024-4f74-89c9-af1ebf556b8d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'><b>Summary of Columns</b><br>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We can use the <b>ColumnSummary</b> function for quickly examining the columns, their datatypes, and summary of NULLs/non-NULLs for a given table. </p>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71dd557-3510-44e7-80e6-4778119d4ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import ColumnSummary\n",
    "obj = ColumnSummary(data=tdf,\n",
    "                        target_columns=[':']\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6ae4d-b5cd-4741-b04f-c05225bee86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.result.head(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4fcb51-a52e-4ead-9e7d-a9c63aaf7fda",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>4. Exploratory Data Analysis</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c523a8-b5a9-40a0-9bbf-de2e7055cf4c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Exploratory Data Analysis (EDA) is a process where we visually and statistically examine, analyze, and summarize data to comprehend its characteristics, patterns, and relationships. This approach is crucial for gaining insights and a deeper understanding of the dataset at hand.<br>First let us analyse the Gender and Churn distributions in our data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae28b3-4a8a-4a67-b4c8-3fdcc92e8b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=tdf.select(['Gender','CustomerID']).groupby('Gender').count()\n",
    "d1 = d1.assign(drop_columns=True,\n",
    "          Gender=d1.Gender,\n",
    "          Count=d1.count_CustomerID)\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd912c-034f-4c2b-bdeb-71327792a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2=tdf.select(['Churn','CustomerID']).groupby('Churn').count()\n",
    "d2 = d2.assign(drop_columns=True,\n",
    "          Churn=d2.Churn,\n",
    "          Count=d2.count_CustomerID)\n",
    "d2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2638bf-3a42-4b87-91a3-a1ae0b18c034",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "We can see that the aggregated data is available to us in teradataml dataframe. Let's visualize this data to better understand the Churn and gender distributions. Clearscape Analytics can easily integrate with 3rd party visualization tools like Tableau, PowerBI or many python modules available like plotly, seaborn etc. We can do all the calculations and pre-processing on Vantage and pass only the necessary information to visulazation tools, this will not only make the calculation faster but also reduce the overall time due to less data movement between tools.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1551f21e-5e8b-4eaa-9049-e5572588aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=d1.to_pandas().reset_index()\n",
    "d2=d2.to_pandas().reset_index()\n",
    "#Gender and Churn percentage distribution\n",
    "# Create subplots: use 'domain' type for Pie subplot\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "fig.add_trace(go.Pie(labels=d1['Gender'], values=d1['Count'], name=\"Gender\"),\n",
    "              1, 1)\n",
    "fig.add_trace(go.Pie(labels=d2['Churn'], values=d2['Count'], name=\"Churn\"),\n",
    "              1, 2)\n",
    "\n",
    "# Use `hole` to create a donut-like pie chart\n",
    "fig.update_traces(hole=.4, hoverinfo=\"label+percent+name\", textfont_size=16)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Gender and Churn Distributions\",\n",
    "    # Add annotations in the center of the donut pies.\n",
    "    annotations=[dict(text='Gender', x=0.16, y=0.5, font_size=20, showarrow=False),\n",
    "                 dict(text='Churn', x=0.84, y=0.5, font_size=20, showarrow=False)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b67f499-fb3f-4327-a2fa-2a6903f9259f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>From the above plot we can see that 26.6 % of customers switched to another firm.<br>And of total customers 49.5 % are female and 50.5 % are male.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9036a5d3-a6d1-46b6-92de-2e26a2e02f70",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Now, let us see the chrun with respect to gender.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2670a8-ae57-4510-8a16-f83dc863cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "d3=tdf.select(['Churn','Gender','CustomerID']).groupby(['Churn','Gender']).count()\n",
    "d3 = d3.assign(drop_columns=True,\n",
    "          Churn=d3.Churn,\n",
    "          Gender=d3.Gender,     \n",
    "          Count=d3.count_CustomerID)\n",
    "d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93edbaec-0dde-483f-987c-6adb84d1d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d3=d3.to_pandas().reset_index()\n",
    "fig2=px.sunburst(d3,path=['Churn','Gender'],values='Count')\n",
    "fig2.update_layout(\n",
    "    title_text=\"Churn Distribution w.r.t Gender\")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f53f2c-4ca1-4e88-90cd-fe262768f7cb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>We can see that there is negligible difference in customer count who changed the service provider. Both genders behaved in similar fashion when it comes to migrating to another service provider.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84104565-b183-43d7-b3c0-7d29bb56a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "d4=tdf.select(['Churn','Contract','CustomerID']).groupby(['Churn','Contract']).count()\n",
    "d4 = d4.assign(drop_columns=True,\n",
    "          Churn=d4.Churn,\n",
    "          Contract=d4.Contract,     \n",
    "          Count=d4.count_CustomerID)\n",
    "d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc01721-c739-4f06-bd1e-cfd04a21ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "d4=d4.to_pandas().reset_index()\n",
    "fig4 = px.bar(d4,x=\"Churn\",y=\"Count\", color=\"Contract\", barmode=\"group\", title=\"<b>Customer contract distribution<b>\")\n",
    "fig4.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159eb48b-d69b-4424-b2d8-19156980b2a6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> We can see that about 75% of customer with Month-to-Month Contract opted to move out as compared to 13% of customers with One Year Contract and 3% with Two Year Contract.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b2b1d-2717-4118-bc51-ceda24f848ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "d5=tdf.select(['PaymentMethod','CustomerID']).groupby('PaymentMethod').count()\n",
    "d5 = d5.assign(drop_columns=True,\n",
    "          PaymentMethod=d5.PaymentMethod,\n",
    "          Count=d5.count_CustomerID)\n",
    "d5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89680a18-c99a-4814-bf6b-cfec26e3a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "d5=d5.to_pandas().reset_index()\n",
    "fig5 = go.Figure(data=[go.Pie(labels=d5['PaymentMethod'], values=d5['Count'], hole=.3)])\n",
    "fig5.update_layout(title_text=\"<b>Payment Method Distribution</b>\")\n",
    "fig5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c181a-4f17-4fd6-af19-5a04d54649d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d6=tdf.select(['Churn','PaymentMethod','CustomerID']).groupby(['Churn','PaymentMethod']).count()\n",
    "d6 = d6.assign(drop_columns=True,\n",
    "          Churn=d6.Churn,\n",
    "          PaymentMethod=d6.PaymentMethod,     \n",
    "          Count=d6.count_CustomerID)\n",
    "d6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32510236-fc88-49b0-994f-10f3e068cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d6=d6.to_pandas().reset_index()\n",
    "fig6 = px.bar(d6,x=\"Churn\",y=\"Count\", color=\"PaymentMethod\", barmode=\"stack\", title=\"<b>Customer Payment Method distribution w.r.t. Churn<b>\")\n",
    "fig6.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdeb685-be22-4ea8-a58c-720526cb673b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Major customers who moved out were having Electronic Check as Payment Method.\n",
    "<br>Customers who opted for Credit-Card automatic transfer or Bank Automatic Transfer and Mailed Check as Payment Method were less likely to move out. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83d0437-504d-4570-b078-d4121de56026",
   "metadata": {},
   "outputs": [],
   "source": [
    "d7=tdf.select(['Churn','InternetService','Gender','CustomerID']).groupby(['Churn','InternetService','Gender']).count()\n",
    "d7 = d7.assign(drop_columns=True,\n",
    "          Churn=d7.Churn,\n",
    "          InternetService=d7.InternetService, \n",
    "          Gender=d7.Gender,\n",
    "          Count=d7.count_CustomerID)\n",
    "d7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e81994-b312-46a6-98d1-1b951f6ad48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d7.sort([\"InternetService\"]).head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89598374-e142-4145-b446-0875a94db099",
   "metadata": {},
   "outputs": [],
   "source": [
    "d7=d7.to_pandas().reset_index()\n",
    "fig7 = go.Figure()\n",
    "\n",
    "for t in d7['Churn'].unique():\n",
    "    dfp = d7[d7['Churn']==t]\n",
    "    fig7.add_traces(go.Bar(x=[dfp['InternetService'], dfp['Gender']],\n",
    "                          y=dfp['Count'],\n",
    "                          width=0.75,\n",
    "                          customdata=d7['Churn'],\n",
    "                          name='Churn :' +str(dfp['Churn'].values[0]) \n",
    "                         )\n",
    "                  )\n",
    "\n",
    "fig7.update_layout(barmode='stack',\n",
    "                  title_text=\"<b>Churn Distribution w.r.t. Internet Service and Gender</b>\")\n",
    "fig7.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e186c-ce1c-4034-bf46-116382ba79fa",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> We can see that a lot of customers choose the Fiber optic service as compared to DSL but it's also evident that the customers who use Fiber optic have high churn rate, this might suggest a dissatisfaction with this type of internet service.\n",
    "<br> Customers having DSL service have less churn rate compared to Fiber optic service.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ad5ab-94da-46fc-8fd2-9929082a0d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d8=tdf.select(['Churn','Dependents','CustomerID']).groupby(['Churn','Dependents']).count()\n",
    "d8 = d8.assign(drop_columns=True,\n",
    "          Churn=d8.Churn,\n",
    "          Dependents=d8.Dependents,\n",
    "          Count=d8.count_CustomerID)\n",
    "d8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c4ff03-c81b-4bc8-8ce7-f18ce1fbbd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "d8=d8.to_pandas().reset_index()\n",
    "color_map = {\"Yes\": \"#FF97FF\", \"No\": \"#AB63FA\"}\n",
    "fig8 = px.bar(d8, x=\"Churn\",y=\"Count\", color=\"Dependents\", barmode=\"group\", title=\"<b>Dependents distribution</b>\", color_discrete_map=color_map)\n",
    "fig8.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig8.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c171e4-e3a4-471d-ae35-4c5d361655c4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Customers without dependents are more likely to churn.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983756f-bd63-4ef0-a892-81970fab37e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d9=tdf.select(['Churn','Partner','CustomerID']).groupby(['Churn','Partner']).count()\n",
    "d9 = d9.assign(drop_columns=True,\n",
    "          Churn=d9.Churn,\n",
    "          Partner=d9.Partner,\n",
    "          Count=d9.count_CustomerID)\n",
    "d9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20368d1-b414-4dde-87ab-3e817437d231",
   "metadata": {},
   "outputs": [],
   "source": [
    "d9=d9.to_pandas().reset_index()\n",
    "color_map = {\"Yes\": '#FFA15A', \"No\": '#00CC96'}\n",
    "fig9 = px.bar(d9, x=\"Churn\",y=\"Count\", color=\"Partner\", barmode=\"group\", title=\"<b>Chrun distribution w.r.t. Partners</b>\", color_discrete_map=color_map)\n",
    "fig9.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig9.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89814b-71fd-4041-8ff4-ef77da2a51d2",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Customers that don't have partners are more likely to churn.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c574c3e-f963-4dea-802d-6be81eb12c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d10=tdf.select(['Churn','PaperlessBilling','CustomerID']).groupby(['Churn','PaperlessBilling']).count()\n",
    "d10 = d10.assign(drop_columns=True,\n",
    "          Churn=d10.Churn,\n",
    "          PaperlessBilling=d10.PaperlessBilling,\n",
    "          Count=d10.count_CustomerID)\n",
    "d10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3807c742-9417-4628-9efd-7fc166581b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d10=d10.to_pandas().reset_index()\n",
    "color_map = {\"Yes\": '#FFA15A', \"No\": '#00CC96'}\n",
    "fig10 = px.bar(d10, x=\"Churn\",y=\"Count\", color=\"PaperlessBilling\",  title=\"<b>Chrun distribution w.r.t. Paperless Billing</b>\", color_discrete_map=color_map)\n",
    "fig10.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig10.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a30bd2-ff32-4977-904c-a1e718ca4aab",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Customers with Paperless Billing are most likely to churn.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cea3b7-53ec-4cae-bbe6-1e8c9809329b",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>5. Feature Engineering</b>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>Teradata Enterprise Feature Store (EFS) Functions are designed to handle feature management within the Vantage environment. While inspired by the syntax of Feast, Teradata EFS Functions stands out, offering efficiency and robustness in data management and feature handling tailored specifically for the use of Teradata Vantage. Teradata EFS Functions use Teradata Dataframes for Feature management, to the contrary of the pandas dataframe of Feast. With Teradata Dataframes we avoid extracting the data to create or use Features from the Enterprise Feature Store (EFS). The EFS Functions are crafted to empower Data Science teams for effective and streamlined feature management. This notebook will walk you through the capabilities of EFS Functions, demonstrating how it integrates seamlessly with your data models and processes.</p>\n",
    "\n",
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>5.1 Setup a Feature Store Repository</b>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>The Enterprise Feature Store (EFS) SDK is designed with a totally object-oriented approach, focusing on intuitive interaction with feature stores. Central to this design are several core objects: Feature, Entity, DataSource, FeatureGroup. Together, these objects facilitate the efficient management and utilization of features within your data ecosystem, leveraging Teradata Vantage for metadata storage.</p>\n",
    "<p style='font-size:16px;font-family:Arial;'>A feature store repository serves as the foundational environment for storing and managing your data features. The owner of the FeatureStore can grant/revoke read only, write only or read and write authorization to other user(s)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4a190-ec1e-4096-a971-8aaf0c88e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_fs = FeatureStore(repo='TelcoFS')\n",
    "telco_fs.setup(perm_size='10e8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67198974-3bc5-4b8b-b2e3-dcde9b856d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List whether FeatureStore is setup or not.\n",
    "telco_fs.list_repos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bfdbc2-bc48-4656-a219-45375b66984b",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.2 Create and Register Entity </b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3f98cc-084f-4366-8e1d-24f58481172d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let us now start with feature engineering, for which we will create the required columns in the dataframe and than use those columns to register as features in the feature group of feature store created in the step above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c320bde7-a699-4d1b-9e33-0d232f960fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(in_schema(\"DEMO_Telco\", \"Customer_Churn\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8614a6-b143-4713-a003-433e75572e7e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>This code performs the following operations:</p>\n",
    "    <ol style = 'font-size:16px;font-family:Arial;'>\n",
    "        <li><strong>Assigning New Values:</strong> The <code>df.assign()</code> function is used to create new columns or modify existing ones in the DataFrame <code>df</code>.</li>\n",
    "        <li><strong>Replacing Values:</strong>\n",
    "            <ul>\n",
    "                <li><span class=\"highlight\">MultipleLines</span>: Replaces \"No phone service\" with \"No\".</li>\n",
    "                <li><span class=\"highlight\">OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies</span>: Replaces \"No internet service\" with \"No\" for each of these columns.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>Converting Churn Values:</strong>\n",
    "            <ul>\n",
    "                <li><span class=\"highlight\">Churn</span>: Uses the <code>case</code> function to convert \"Yes\" to 1 and \"No\" to 0. If the value is neither \"Yes\" nor \"No\", it defaults to 0.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>Displaying the DataFrame:</strong> The final <code>df</code> statement displays the modified DataFrame.</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d37dc4-9d88-4710-a6cb-7d655d7bd461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tdf.assign(\n",
    "    MultipleLines = tdf.MultipleLines.replace(\"No phone service\",\"No\"),\n",
    "    OnlineSecurity = tdf.OnlineSecurity.replace(\"No internet service\",\"No\"),\n",
    "    OnlineBackup = tdf.OnlineBackup.replace(\"No internet service\",\"No\"),\n",
    "    DeviceProtection = tdf.DeviceProtection.replace(\"No internet service\",\"No\"),\n",
    "    TechSupport = tdf.TechSupport.replace(\"No internet service\",\"No\"),\n",
    "    StreamingTV = tdf.StreamingTV.replace(\"No internet service\",\"No\"),\n",
    "    StreamingMovies = tdf.StreamingMovies.replace(\"No internet service\",\"No\"),\n",
    "    Churn = case({ \"Yes\" : 1, \"No\" : 0}, value=tdf.Churn,else_=0)\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ea53b-6e8a-41b4-a8ca-097fbb930441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ConvertTo(\n",
    "    data=df,\n",
    "    target_columns=['CustomerID', 'Gender', 'Partner', 'Dependents', 'PhoneService',\n",
    "                    'MultipleLines', 'InternetService','OnlineSecurity', 'OnlineBackup',\n",
    "                    'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
    "                    'Contract', 'PaperlessBilling', 'PaymentMethod'],\n",
    "    target_datatype=[\"VARCHAR(charlen=10,charset=UNICODE,casespecific=NO)\"]\n",
    ").result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13e7800-31a5-4050-be00-fa0b3ebb6627",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let's store the transformed data to table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1767fc-c6c6-465a-bef4-acc87eb2e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(\n",
    "    df=df,\n",
    "    table_name='transformed_data_automl',\n",
    "    if_exists='replace'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f06dc0-e762-4808-83f7-c6ee6fe3a59c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Now we will proceed to save the features as well as the feature processing logic in feature store.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>This will allow us to re-use the features and processing later-on, avoiding to re-write the processing logic.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db98cf-cd21-4f7b-9e39-cc2a0eef5751",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame('transformed_data_automl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81de7ec-bdf5-46c0-b9c3-6e82e4d17e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create entity for DataFrame 'patient_profile_df'\n",
    "entity=Entity(name='CustId', columns=df.CustomerID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae90b3-1a2b-4783-a87e-3cbbf64a2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the Entity.\n",
    "telco_fs.apply(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a7638-0879-42d7-9f24-46a751da5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at existing Entities after registering the Entity.\n",
    "telco_fs.list_entities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5672211-fdb8-40e8-b26d-e0c076232b89",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.3 Create and Register FeatureGroup </b></p>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>FeatureGroup can be created using Teradata DataFrame.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>FeatureGroup can be created using SQL Query. </li>\n",
    "<li style = 'font-size:16px;font-family:Arial;'>FeatureGroup can be created using objects of Feature, Entity, DataSource.  </li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3ad9ab-22b7-4c49-b2fa-50edd93ec6cd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'><b>Creating a FeatureGroup from Teradata DataFrame\n",
    "</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08597b7-00db-46c8-8722-f1881b22f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_fg = FeatureGroup.from_DataFrame(\n",
    "    name='TelcoFG', \n",
    "    entity_columns='CustomerID', \n",
    "    df=df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bdc2a5-b441-4ca3-937b-6604020508b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at Properties.\n",
    "telco_fg.features, telco_fg.entity, telco_fg.data_source, telco_fg.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9069c2fc-6e47-4d44-b5bf-f1c3efa9ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_fs.apply(telco_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8867efb-13ab-4cf7-9924-60b31f911d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_fs.list_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf5904-1dcc-46c1-bd3d-5be5f1001ec0",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>5.4 Reuse features from Enterprise Feature Store with teradataml analytic functions for AutoML processing.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7cff1-4b1b-466c-8836-5e35d61763cd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Since FeatureStore stores DataSource also, you can retrive Teradata DataFrame from FeatureStore. <br> `FeatureStore.get_dataset()` get's Teradata DataFrame from FeatureGroup.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13015d-d3d1-4bc5-9d13-cf813e03dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataSet for FeatureGroup TelcoFG. \n",
    "df = telco_fs.get_dataset('TelcoFG')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaca5d6-2e5a-400f-a653-cbf70c1564c8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> We have our training dataset which is created, with all the feature engineering</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'> We can see from that the column Multiple lines has only two values yes and no. The same features can also be re-used accross multiple use-cases and models without any data preperation</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f6bf8f-b9e1-441a-b089-c1ceebdbc059",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>We split the dataset in to training and testing dataset with 80:20 split ratio.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f3a51-60a2-4b80-8f82-a77d8adcc322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Performing sampling to get 80% for trainning and 20% for testing\n",
    "tdf_sample = df.sample(frac = [0.8, 0.2])\n",
    "\n",
    "# Fetching train and test data\n",
    "tdf_train= tdf_sample[tdf_sample['sampleid'] == 1].drop('sampleid', axis=1)\n",
    "tdf_test = tdf_sample[tdf_sample['sampleid'] == 2].drop('sampleid', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86ae3c5-c44c-4c1d-bf08-c8e8d3d83d58",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>6. AutoML Training</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e3e67-6a98-4f1f-8479-45a637ca0bb5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>AutoML (Automated Machine Learning) is an approach that automates the process of building, training, and validating machine learning models. It involves various algorithms to automate various aspects of the machine learning workflow, such as data preparation, feature engineering, model selection, hyperparameter tuning, and model deployment. It aims to simplify the process of building machine learning models, by automating some of the more time-consuming and labor-intensive tasks involved in the process.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We create a <code>AutoClassifier</code> instance which is a special purpose AutoML feature to run classification specific tasks. We use the <code>exclude</code> parameter to specify model algorithms to be excluded from model training phase. Here we exclude the 'knn' model. The <code>max_runtime_secs</code> specifies the time limit in seconds for model training.\n",
    "<br><br>\n",
    "<code>verbose</code>: specifies the detailed execution steps based on verbose level as follows:\n",
    "</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li><b>0</b>: prints the progress bar and leaderboard</li>\n",
    "    <li><b>1</b>: prints the execution steps of AutoML.</li>\n",
    "    <li><b>2</b>: prints the intermediate data between the execution of each step of AutoML.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddce4f43-4035-44af-ba24-4944f7705a9c",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>6.1. AutoML Training</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b86886-ba91-4e36-9d0f-b0415dd59ccd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>AutoML (Automated Machine Learning) is an approach that automates the process of building, training, and validating machine learning models. It involves various algorithms to automate various aspects of the machine learning workflow, such as data preparation, feature engineering, model selection, hyperparameter tuning, and model deployment. It aims to simplify the process of building machine learning models, by automating some of the more time-consuming and labor-intensive tasks involved in the process.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We create a <code>AutoClassifier</code> instance which is a special purpose AutoML feature to run classification specific tasks. We use the <code>exclude</code> parameter to specify model algorithms to be excluded from model training phase. Here we exclude the 'knn' model. The <code>max_runtime_secs</code> specifies the time limit in seconds for model training.\n",
    "<br><br>\n",
    "<code>verbose</code>: specifies the detailed execution steps based on verbose level as follows:\n",
    "</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><b>0</b>: prints the progress bar and leaderboard</li>\n",
    "    <li><b>1</b>: prints the execution steps of AutoML.</li>\n",
    "    <li><b>2</b>: prints the intermediate data between the execution of each step of AutoML.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8137fc-7250-427f-92c7-6070a8ffddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating AutoClassifier Instance\n",
    "# Selecting 'Auto' mode for AutoML training\n",
    "# Excluding knn,glm and svm model from default model list for training\n",
    "# Used early stopping timer criteria with value 600 sec\n",
    "\n",
    "aml = AutoClassifier(\n",
    "    exclude          = ['knn','svm'],\n",
    "    verbose          = 2,\n",
    "    max_runtime_secs = 600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e64a2e-648d-4321-8bd6-5bdd8051cbb6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b><i>Note: Since the AutoML functionality does a lot of steps like Feature exploration and Data Preparation along with Model Training and Evaluating to select the Best model the below step may take anywhere between 12-15 minutes</i></b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378743d2-daae-4a91-af06-fbd566072902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fitting train data \n",
    "aml.fit(data = tdf_train, target_column = 'Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea7b521-d7c1-4994-b380-b0308c85743d",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial'>6.2. Model Leaderboard Generation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4223d717-dd65-449f-8c2b-c415e1471ac3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Here, we generate model leaderboard and leader for a given dataset. Leaderboard is a ranked table with a list of models with all their evaluation metrics.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d69751-fe5e-46dd-9c24-3322a5bd1487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fetching leaderboard\n",
    "\n",
    "leaderboard = aml.leaderboard()\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a330d76-3671-42f0-a2e3-e0b7f2138048",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial'>6.3 Best Performing Model</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cbeea7-d5d8-4333-b25a-8a02aa4b4cff",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The following function displays the best performing model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054141f-3c2e-47be-b9db-aef8b4c3424d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fetching best performing model\n",
    "aml.leader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a1096f-7c8b-4e2f-b028-aa7f89c22f15",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>7. Prediction</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a2ffe3-91f5-4da0-ac6c-6276323e4eb3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The predict function generates predictions using either the default test data or any specified dataset, based on the model's rank in the leaderboard, and displays the performance metrics of the chosen model. If the test data contains a target column, both predictions and performance metrics are displayed; otherwise, only the predictions are shown.\n",
    "<br><br>\n",
    "You can also use the <code>rank</code> parameter in the predict function. The <code>rank</code> parameter specifies the model's rank in the leaderboard to be used for prediction. By default, the rank is set to 1, meaning the best-performing model is used.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59aef4-2d38-4f4c-a3bc-eba294fd0405",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial'>7.1 Generating prediction on test data using Best Model</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056065c-5b4a-4ee4-8473-2bc9f0dfed4f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Here, we specify the <code>tdf_test</code> dataset for prediction. When using external data instead of the default test data, the predict function applies all the data transformation steps performed during the training phase on the external data before passing the data to the model for prediction.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31562da-23fa-468c-97da-c8993fb70b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching prediction and metrics on test data\n",
    "prediction = aml.predict(tdf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b07040-433e-4810-bfb8-6daacdd2f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing prediction\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10daa63d-8de1-41b5-8f02-e97ce021ed79",
   "metadata": {},
   "source": [
    "<b style = 'font-size:18px;font-family:Arial'>Generating predictions using 2nd Best Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a723d21-9033-4716-8b9f-dc690235b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction using the second best performing model\n",
    "prediction_second = aml.predict(tdf_test, rank=2)\n",
    "\n",
    "#Printing prediction\n",
    "prediction_second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263fc174-9bcb-400f-9683-a67b707bf7f7",
   "metadata": {},
   "source": [
    "<b style = 'font-size:18px;font-family:Arial'>Generating predictions using 3rd Best Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038aedc8-e8e7-42e6-a646-cc075d53e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_third = aml.predict(tdf_test, rank=3)\n",
    "\n",
    "#Printing prediction\n",
    "prediction_third"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65565566-d8a4-4c19-9cd8-be703eb75ece",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none\">\n",
    "<b style = 'font-size:18px;font-family:Arial'>7.2 Generating and Comparing ROC for the Top 3 Models</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a975ee-d64b-4aca-aa42-d084e4671422",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The ROC curve is a graph between TPR(True Positive Rate) and FPR(False Positive Rate). The area under the ROC curve measures how well the model can distinguish between positive and negative classes. The higher the AUC, the better the model's performance in distinguishing between the positive and negative categories. AUC above 0.75 is generally considered decent.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f437d8-ef5e-41b8-b61c-073637e2bf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating True-Positive Rate (TPR), False-Positive Rate (FPR), Threshold_values for both the models\n",
    "roc_first = ROC(\n",
    "    probability_column = \"prob_1\",\n",
    "    observation_column = \"Churn\",\n",
    "    positive_class = '1',\n",
    "    num_thresholds = 100,\n",
    "    data = prediction\n",
    ")\n",
    "\n",
    "roc_second = ROC(\n",
    "    probability_column = \"prob_1\",\n",
    "    observation_column = \"Churn\",\n",
    "    positive_class = '1',\n",
    "    num_thresholds = 100,\n",
    "    data = prediction_second\n",
    ")\n",
    "\n",
    "roc_third = ROC(\n",
    "    probability_column = \"prob_1\",\n",
    "    observation_column = \"Churn\",\n",
    "    positive_class = '1',\n",
    "    num_thresholds = 100,\n",
    "    data = prediction_third\n",
    ")\n",
    "\n",
    "#Getting auc_score for both models\n",
    "auc_first = roc_first.result.get_values()[0][0]\n",
    "auc_second = roc_second.result.get_values()[0][0]\n",
    "auc_third = roc_third.result.get_values()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd238f7d-67ae-4a1a-932b-47db5da338f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first model\n",
    "first_model = leaderboard.MODEL_ID.iloc[0]\n",
    "\n",
    "#second model\n",
    "second_model = leaderboard.MODEL_ID.iloc[1]\n",
    "\n",
    "third_model = leaderboard.MODEL_ID.iloc[2]\n",
    "\n",
    "#Plotting the ROC Curve\n",
    "roc_second.output_data.plot(\n",
    "    x = roc_first.output_data.fpr,\n",
    "    y = [roc_first.output_data.tpr, roc_second.output_data.tpr, roc_third.output_data.tpr,roc_first.output_data.fpr],\n",
    "    legend = [\n",
    "                '{}: AUC = {}'.format(first_model,str(auc_first)),\n",
    "                '{}: AUC = {}'.format(second_model,str(auc_second)),\n",
    "                '{}: AUC = {}'.format(third_model,str(auc_second)),\n",
    "                'Baseline: AUC = {}'.format(str(round(0.5, 4)))\n",
    "             ],\n",
    "    legend_style = 'lower right',\n",
    "    title = 'Receiver Operating Characteristic (ROC) Curve',\n",
    "    xlabel = 'False Positive Rate',\n",
    "    ylabel = 'True Positive Rate',\n",
    "    color = ['green', 'orange', 'blue'],\n",
    "    linestyle = ['-', '-', '--']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d841fcd4-df97-4d31-bd25-28cce37c1a47",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>Conclusion</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e6e4a-ae3a-4249-a6ca-8d644f592db9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We used feature store to store features as well as its processing. We re-used it in model training. The features and processing can be re-used accross multiple machine learning models and use-case , helping to improve data science productivity</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Teradata's AutoML functionality plays a crucial role in this context by automating the complex process of building and deploying machine learning models. AutoML ensures the most optimal preparation and training of models, delivering high-quality machine learning models in minutes. Through hyperparameter tuning (HPT), Teradata's AutoML can automatically select the best parameters for machine learning algorithms using grid search and random search techniques, significantly enhancing model performance.\n",
    "<br><br>\n",
    "By leveraging Teradata's AutoML, companies can save time and reduce costs associated with manual model building and tuning. The technology not only improves the accuracy of predictive models but also democratizes the power of machine learning, allowing customers to utilize advanced analytics without requiring extensive coding or data science expertise. This capability enables companies to swiftly and effectively analyze customer churn data, develop predictive models, and implement proactive strategies to retain customers and enhance their satisfaction.\n",
    "<br><br>\n",
    "In conclusion, Teradata's AutoML functionality is a vital tool for banks aiming to reduce customer churn. By automating and optimizing the machine learning process, Teradata empowers various industries to make data-driven decisions that improve customer retention and drive long-term profitability.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fafdffb-2cde-4d99-8682-9ae64c74497d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>8. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'> <b>Work Tables </b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff3fb9b-4d13-4628-988d-f82463d96537",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['transformed_data']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name=table)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f56a5-e38b-45d7-b532-001de783705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_fs.archive_feature_group(feature_group='TelcoFG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c799b5-f1ef-4349-b0c0-90c2c510c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_fs.delete_feature_group(feature_group='TelcoFG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc238d9-0d01-4ca0-b34a-f802621cb165",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457f9970-b97d-46bc-8be6-cb969da3ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../run_procedure.py \"call remove_data('DEMO_Telco');\" \n",
    "#Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fac6bb-3e3a-488c-848b-41473d6156e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bfa61c-3daa-4d47-b0d7-0a69ef13dc1a",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff7e25c-dc4e-45d7-a67f-8c70e2c517f4",
   "metadata": {},
   "source": [
    "<b style = 'font-size:20px;font-family:Arial'>Required Materials</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Let’s look at the elements we have available for reference for this notebook:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4938d2-5ce6-412e-a665-5d62a3b1a1b5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Filters:</b></p>\n",
    "    <ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><b>Industry:</b> Telco</li>\n",
    "    <li><b>Functionality:</b> Feature Store and AutoML</li>\n",
    "    <li><b>Use Case:</b> Customer Retention</li>\n",
    "    </ul>\n",
    "    <p style = 'font-size:18px;font-family:Arial'><b>Related Resources:</b></p>\n",
    "    <ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><a href = 'https://www.teradata.com/Blogs/NPS-is-a-metric-not-the-goal'>·In the fight to improve customer experience, NPS is a metric, not the goal</a></li>\n",
    "    <li><a href = 'https://www.teradata.com/Blogs/Hyper-scale-time-series-forecasting-done-right'>·Hyper-scale time series forecasting done right</a></li>\n",
    "    <li><a href = 'https://www.teradata.com/Resources/Datasheets/Digital-Identity-Management-and-Great-CX?utm_campaign=i_coremedia-AMS&utm_source=google&utm_medium=paidsearch&utm_content=GS_CoreMedia_NA-US_BKW&utm_creative=Brand-Vantage&utm_term=teradata%20analytic%20platform&gclid=Cj0KCQjwnMWkBhDLARIsAHBOftrWZxDktHkKMsaWjMmNRnQ6Ys-bZBAUhXjWTo1Xa02fsci-IHWBV_waAppkEALw_wcB'>·Close the Gap Between Digital Identity Management and Great Customer Experiences</a></li>\n",
    "        </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fd5272-ceb7-4d47-bd5c-c3aea31e471a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Reference Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'> \n",
    "       <li>Teradata Vantage™ - Analytics Database Analytic Functions - 17.20: <a href = 'https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-VantageTM-Analytics-Database-Analytic-Functions-17.20/Introduction-to-Analytics-Database-Analytic-Functions '>https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-VantageTM-Analytics-Database-Analytic-Functions-17.20/Introduction-to-Analytics-Database-Analytic-Functions </a></li>    \n",
    "  <li>Teradata® Package for Python User Guide - 17.20: <a href = 'https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-Package-for-Python-User-Guide-17.20/Introduction-to-Teradata-Package-for-Python'>https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-Package-for-Python-User-Guide-17.20/Introduction-to-Teradata-Package-for-Python</a></li>\n",
    "  <li>Teradata® Package for Python Function Reference - 17.20: <a href = 'https://docs.teradata.com/r/Enterprise/Teradata-Package-for-Python-Function-Reference-17.20/Teradata-Package-for-Python-Function-Reference'>https://docs.teradata.com/r/Enterprise/Teradata-Package-for-Python-Function-Reference-17.20/Teradata-Package-for-Python-Function-Reference</a></li>      \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b60cb-d919-4daf-bc2a-35d7bf17eec7",
   "metadata": {},
   "source": [
    "<b style = 'font-size:18px;font-family:Arial'>Dataset:</b>\n",
    "\n",
    "- `CustomerID`: unique id of customer\n",
    "- `Gender`: Whether the customer is a male or a female\n",
    "- `SeniorCitizen`:Whether the customer is a senior citizen or not (1, 0)\n",
    "- `Partner`:Whether the customer has a partner or not (Yes, No)\n",
    "- `Dependents`:Whether the customer has dependents or not (Yes, No)\n",
    "- `Tenure`:Number of months the customer has stayed with the company\n",
    "- `PhoneService`:Whether the customer has a phone service or not (Yes, No)\n",
    "- `MultipleLines`:Whether the customer has multiple lines or not (Yes, No, No phone service)\n",
    "- `InternetService`:Customer’s internet service provider (DSL, Fiber optic, No)\n",
    "- `OnlineSecurity`:Whether the customer has online security or not (Yes, No, No internet service)\n",
    "- `OnlineBackup`:Whether the customer has online backup or not (Yes, No, No internet service)\n",
    "- `DeviceProtection`:Whether the customer has device protection or not (Yes, No, No internet service)\n",
    "- `TechSupport`:Whether the customer has tech support or not (Yes, No, No internet service)\n",
    "- `StreamingTV`:Whether the customer has streaming TV or not (Yes, No, No internet service)\n",
    "- `StreamingMovies`:Whether the customer has streaming movies or not (Yes, No, No internet service)\n",
    "- `Contract`:The contract term of the customer (Month-to-month, One year, Two year)\n",
    "- `PaperlessBilling`:Whether the customer has paperless billing or not (Yes, No)\n",
    "- `PaymentMethod`:The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n",
    "- `MonthlyCharges`:The amount charged to the customer monthly\n",
    "- `TotalCharges`:The total amount charged to the customer\n",
    "- `Churn`:Whether the customer churned or not (Yes or No)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e28609-20ff-47e0-a640-48db6a7fa523",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
