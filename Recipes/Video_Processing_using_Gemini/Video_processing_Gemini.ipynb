{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccd454a9-35c3-41a1-9dc5-888d283a3870",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Video Analyzer with Google Gemini\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39b371f-8db0-4e9f-9252-ecc75c3941fc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Video understanding or video insights are crucial across various industries and applications due to their multifaceted benefits. They enhance content analysis and management by automatically generating metadata, categorizing content, and making videos more searchable. Moreover, video insights provide critical data that drive decision-making, enhance user experiences, and improve operational efficiencies across diverse sectors.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Googleâ€™s Gemini 2.0 model brings significant advancements to this field. Beyond its impressive improvements in language processing, this model can handle an enormous input context of up to 1 million tokens. To further its capabilities, Gemini 2.0 is trained as a multimodal model, natively processing text, images, audio, and video. This powerful combination of varied input types and extensive context size opens up new possibilities for processing long videos effectively.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this notebook, we will dive into how Gemini 2.0 can be leveraged for generating valuable video insights, transforming the way we understand and utilize video content across different domains.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Below are the steps needed:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Installing dependencies</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Setting up the Gemini API key</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Importing the libraries</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Saving uploaded files</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Upload videos to the Files API</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Declare functions to be used</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Define tools using the functions created</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Execute the functions to get the video analysis</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Clean up</li>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0337c73-ae4e-447b-9c06-847084a8d00f",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>1. Configuring the environment</b>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>1.1 Install the required libraries</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77725f27-9f84-4eab-84a1-09922b728023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975753b2-0449-4ea7-ba99-a747914d44d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dec9e6-4c1d-48ec-8569-70d9d96b87c4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Note: </b><i>Please restart the kernel after executing these two lines. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b041e3-119c-4c2f-878c-e19709a09dfb",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>1.2 Import the required libraries</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7729e45d-b4a5-4866-86c6-bd9cbaa11600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import google.generativeai as genai_key\n",
    "from IPython.display import Markdown, Audio\n",
    "from teradataml import *\n",
    "import getpass\n",
    "from typing import List\n",
    "from google import genai, generativeai\n",
    "from google.genai import types\n",
    "display.max_rows = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdbc949-a952-469a-82df-3fe49cf35e2e",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>2. Connect to Vantage</b>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>2.1 Connect to Vantage</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d31d6e-d9f7-4d76-84de-5d9d8bcfe4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../UseCases/startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10117773-fc28-481d-969a-1258bed61241",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a4918-ce64-42dc-af5a-4c95691e3129",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>3. Setup API key for Google Gemini</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Please enter the Google API Key, if you don't have one, please get it from <a href = 'https://ai.google.dev/gemini-api/docs/api-key'>here</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f319a4a-6b0d-46d0-9e19-f5b29a61fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = getpass.getpass(prompt = 'Please enter GOOGLE_API_KEY: ')\n",
    "generativeai.configure(api_key = GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5f6894-ea9b-4a2c-b074-f6ead7d1e8c0",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Specify the Gemini model to be used for video analysis. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef5e26-651b-4bb3-81eb-31881f039a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.0-flash-exp\" # @param [\"gemini-1.5-flash-8b\",\"gemini-1.5-flash-002\",\"gemini-1.5-pro-002\",\"gemini-2.0-flash-exp\"] {\"allow-input\":true}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a6936d-01f3-4c06-be98-722bc9aea4c6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Create genai client using the API key. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc4c06-0190-4525-b8e9-7b815a361435",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434b8bee-3f82-4378-9b72-820f6a04a10a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The Gemini API directly accepts video file formats. The File API supports files up to 2GB in size and allows storage of up to 20GB per project. Uploaded files remain available for 2 days and cannot be downloaded from the API.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c048b4-8db1-46f3-9f1b-3cc8c0bdfd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the folder path containing the files you want to upload\n",
    "folder_path = \"./videos\"\n",
    "\n",
    "# Get a list of all files in the folder (optional: filter by file extension if needed)\n",
    "file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, filename))]\n",
    "\n",
    "# file_paths\n",
    "# Loop through each file path and upload it\n",
    "uploaded_files = []\n",
    "for file_path in file_paths:\n",
    "    uploaded_file = client.files.upload(file=file_path)\n",
    "    uploaded_files.append(uploaded_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2fb8cb-f315-47fb-af35-5007deca0f0a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We have uploaded 3 files, the uploaded_files can be seen as below.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f93b6e-b9d1-49d2-9b73-66a5f21e97d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72daf491-17c8-4916-adff-a118b197bd7a",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>4. Setting up and calling prompt on the video</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We will set up the SYSTEM and USER prompts.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d0a9c-c68d-48fb-8fd0-47308c35c3f2",
   "metadata": {
    "id": "dAmrIYI7-d25"
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"When given a video and a query, call the relevant function only once with the appropriate timecodes,name and text for the video\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda4311f-d061-40aa-a08f-ada6e2fa33f6",
   "metadata": {
    "id": "7yb7zdcQ-ibk"
   },
   "outputs": [],
   "source": [
    "USER_PROMPT = \"For each scene in this video, generate text that describe the scene. Place each text into an object with the time of the text in the video.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034b516-3931-4397-b03b-87399069e801",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The <code>generate_content</code> generates a model response given an input GenerateContentRequest. Using the SYSTEM_PROMPT and USER_PROMPT we execute the function. Safety ratings and content filtering are reported for both prompt in GenerateContentResponse.prompt_feedback and for each candidate in finishReason and in safetyRatings. The API: - Returns either all requested candidates or none of them - Returns no candidates at all only if there was something wrong with the prompt (check promptFeedback) - Reports feedback on each candidate in finishReason and safetyRatings.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c3aa30-f616-4247-8da8-00b95020774c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NlJ9NwRGT6d1",
    "outputId": "30eadeaa-5fbb-4081-9a03-64a259a177b8"
   },
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "data=''\n",
    "for file_upload in uploaded_files:\n",
    "    print(file_upload.uri)\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL_ID,\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part.from_uri(\n",
    "                        file_uri=file_upload.uri,\n",
    "                        mime_type=file_upload.mime_type),\n",
    "                    ]),\n",
    "            USER_PROMPT,\n",
    "        ],\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=SYSTEM_PROMPT,\n",
    "            temperature=0.0,\n",
    "        ),\n",
    "    )\n",
    "    print(response.text)\n",
    "\n",
    "    data += response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683d903-abe9-45e4-856e-6e2747189279",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ced3d-20ea-4c79-b9d1-02105bae7b6a",
   "metadata": {
    "id": "Y0DjyUkb_GCR"
   },
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>5. Function Calls to get back the data in a way we expect it</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Using the Gemini API function calling feature, you can provide custom function definitions to the model. The model doesn't directly invoke these functions, but instead generates structured output that specifies a function name and suggested arguments. You can then use the function name and arguments to call an external API, and you can incorporate the resulting API output into a further query to the model, enabling the model to provide a more comprehensive response and take additional actions.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Function calling empowers users to interact with real-time information and services like databases, customer relationship management systems, and document repositories. The feature also enhances the model's ability to provide relevant and contextual answers. Function calling is best for interacting with external systems. If your use case requires the model to perform computation but doesn't involve external systems or APIs, you should consider using code execution instead.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e93a5-0bb7-462f-a45f-2ef193a008d1",
   "metadata": {
    "id": "TXJmm1XeuypD"
   },
   "outputs": [],
   "source": [
    "set_timecodes = types.FunctionDeclaration(\n",
    "    name=\"set_timecodes\",\n",
    "    description=\"Set the timecodes for the video with associated text\",\n",
    "    parameters={\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"timecodes\": {\n",
    "                \"type\": \"ARRAY\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"OBJECT\",\n",
    "                    \"properties\": {\n",
    "                        \"time\": {\"type\": \"STRING\"},\n",
    "                        \"text\": {\"type\": \"STRING\"},\n",
    "                    },\n",
    "                    \"required\": [\"time\", \"text\"],\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"timecodes\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "set_timecodes_with_objects = types.FunctionDeclaration(\n",
    "    name=\"set_timecodes_with_objects\",\n",
    "    description=\"Set the timecodes for the video with associated text and object list\",\n",
    "    parameters={\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"timecodes\": {\n",
    "                \"type\": \"ARRAY\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"OBJECT\",\n",
    "                    \"properties\": {\n",
    "                        \"time\": {\"type\": \"STRING\"},\n",
    "                        \"text\": {\"type\": \"STRING\"},\n",
    "                        \"objects\": {\n",
    "                            \"type\": \"ARRAY\",\n",
    "                            \"items\": {\"type\": \"STRING\"},\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"time\", \"text\", \"objects\"],\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"timecodes\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "set_timecodes_with_numeric_values = types.FunctionDeclaration(\n",
    "    name=\"set_timecodes_with_numeric_values\",\n",
    "    description=\"Set the timecodes for the video with associated numeric values\",\n",
    "    parameters={\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"timecodes\": {\n",
    "                \"type\": \"ARRAY\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"OBJECT\",\n",
    "                    \"properties\": {\n",
    "                        \"time\": {\"type\": \"STRING\"},\n",
    "                        \"value\": {\"type\": \"NUMBER\"},\n",
    "                    },\n",
    "                    \"required\": [\"time\", \"value\"],\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"timecodes\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "set_timecodes_with_descriptions = types.FunctionDeclaration(\n",
    "    name=\"set_timecodes_with_descriptions\",\n",
    "    description=\"Set the timecodes for the video with associated spoken text and visual descriptions\",\n",
    "    parameters={\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"timecodes\": {\n",
    "                \"type\": \"ARRAY\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"OBJECT\",\n",
    "                    \"properties\": {\n",
    "                        \"time\": {\"type\": \"STRING\"},\n",
    "                        \"spoken_text\": {\"type\": \"STRING\"},\n",
    "                        \"visual_description\": {\"type\": \"STRING\"},\n",
    "                    },\n",
    "                    \"required\": [\"time\", \"spoken_text\", \"visual_description\"],\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"timecodes\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc9d73e-11d7-499d-b01c-fecb76aac6af",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Using the functions declared we will create tools for the video analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45869b8f-cb63-4d46-8703-0844aaed959d",
   "metadata": {
    "id": "IsT-tG2N8bEP"
   },
   "outputs": [],
   "source": [
    "video_tools = types.Tool(\n",
    "    function_declarations=[set_timecodes, set_timecodes_with_objects, set_timecodes_with_numeric_values],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60851c4d-5eed-4dcf-ad49-8fe128575eba",
   "metadata": {
    "id": "CUHJB9PWCTXr"
   },
   "outputs": [],
   "source": [
    "\n",
    "def set_timecodes_func(timecodes):\n",
    "    return [{**t, \"text\": t[\"text\"].replace(\"\\\\'\", \"'\")} for t in timecodes]\n",
    "\n",
    "def set_timecodes_with_objects_func(timecodes):\n",
    "    return [{**t, \"text\": t[\"text\"].replace(\"\\\\'\", \"'\")} for t in timecodes]\n",
    "\n",
    "def set_timecodes_with_descriptions_func(timecodes):\n",
    "    return [{**t, \"text\": t[\"spoken_text\"].replace(\"\\\\'\", \"'\")} for t in timecodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718126d0-01ff-41f1-bfed-32803b701de5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "71ieYrnEAp1u",
    "outputId": "4c5a8e92-ba91-4b9a-a8b1-9d4e6944fcd5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "USER_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dd87bb-d564-4124-ab26-283c0a6145f5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will generate the response for the 3 video files uploaded and create a dataframe using the response.</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd36767-f57f-4881-84e2-916d2b723d90",
   "metadata": {
    "id": "wEitIone_flU"
   },
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "data={}\n",
    "i=0\n",
    "df_index=''\n",
    "for file_upload in uploaded_files:\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL_ID,\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part.from_uri(\n",
    "                        file_uri=file_upload.uri,\n",
    "                        mime_type=file_upload.mime_type),\n",
    "                    ]),\n",
    "            USER_PROMPT,\n",
    "        ],\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=SYSTEM_PROMPT,\n",
    "            tools=[video_tools],\n",
    "            temperature=0,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    response.candidates[0].content.parts[0].function_call\n",
    "    # print(response.candidates[0].content.parts[0])\n",
    "    df_index = 'video_'+str(i)\n",
    "    i=i+1\n",
    "    # print(df_index)      \n",
    "    if (len(data) == 0):\n",
    "        data = response.candidates[0].content.parts[0].function_call.args\n",
    "        data_1 = response.candidates[0].content.parts[0].function_call.args\n",
    "        data_1.update(video_no= df_index)\n",
    "        # df1 = pd.DataFrame(data_1['timecodes'], index=index_var)\n",
    "        df1 = pd.json_normalize(data_1, \"timecodes\",\"video_no\")\n",
    "        # df = pd.DataFrame(data['timecodes'])\n",
    "        # df.append(df_index)\n",
    "        # print(df1)\n",
    "    else:    \n",
    "        # data.append(response.candidates[0].content.parts[0].function_call.args)\n",
    "        data.update(response.candidates[0].content.parts[0].function_call.args)\n",
    "        data_1.update(response.candidates[0].content.parts[0].function_call.args)\n",
    "        data_1.update(video_no= df_index)\n",
    "        df1 = pd.concat([df1,pd.json_normalize(data_1, \"timecodes\",\"video_no\")])\n",
    "        # df = pd.concat([df,pd.DataFrame(data['timecodes'])])\n",
    "        # df.append(df_index)\n",
    "    # print(df)    \n",
    "# df.index = df_index\n",
    "# index_var=['video_0','video_1','video_2']\n",
    "# print(index_var)\n",
    "# df\n",
    "# df.index = index_var\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cff7b7-0f5b-4fac-86b7-3a76177ee28a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The above data from the dataframe can be stored into Vantage table using <code>copy_to_sql</code> functions. The data can be used for futher analysis in Vantage using the various In-Db Clearscape Analytic functions available in Vanatge.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>For reference we have included 1 video file here so that we can verify the transcripts generated by using the Gemini model for the video files.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36761941-19cc-4408-8b4c-e2c1ad419d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"./videos/RoadAccidents004_x264.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2798c8c8-67c6-434a-a607-1e8ba84afe8a",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>6. Cleanup</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following code will clean up the video files uploaded to Google Gemini.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240665c-4d7d-4de6-a0f3-49b67d96abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for file_upload in uploaded_files:\n",
    "        generativeai.delete_file(file_upload.name)\n",
    "        print(f'Deleted {file_upload.name }.')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2a529-bfb6-4a75-9461-9f0bdb110fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac05203d-5f55-4d21-94ed-10946287770d",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analyticsâ„¢</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright Â© Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
