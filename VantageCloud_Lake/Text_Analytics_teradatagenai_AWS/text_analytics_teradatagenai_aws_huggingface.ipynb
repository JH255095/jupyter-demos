{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "      Simplify Text Analytics with Teradata Python package for Generative AI\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>Introduction:</b></p>\n",
    "\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "  The <code>teradatagenai</code> Python library enables data scientists, analysts, and developers to run analytics on their unstructured data directly within Teradata VantageCloud. It's built-in support for open-source Hugging Face models through Teradata's  Bring Your Own Large Language Model (BYOLLM) capability and cloud service provider or by using In-DB TextAnalytics AI functions to access models provided by AWS, Azure, and GCP.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"./images/teradatagenai.png\" width=\"1000\" alt=\"teradatagenai Diagram\" style=\"border:4px solid #404040; border-radius: 10px;\">\n",
    "</div>\n",
    "\n",
    "<p style=\"font-size:20px;font-family:Arial;margin-top:10px\"><b>Business Value:</b></p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    " Organizations handle massive volumes of unstructured text including emails, voice call transcripts, customer reviews, contracts and more. Traditional approaches to analyze this data often involve costly data transfers, building custom ML pipelines, and extended turnaround times. <code>teradatagenai</code> addresses these challenges by bringing domain specific language models LLMs and hosted LLMs closer to your data.\n",
    "</p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "  With built-in support for GPU acceleration and seamless integration with VantageCloud, the library offers simple function calls that abstract complex APIs, enabling secure, scalable, and performant text processing. Whether you're deploying open source models in-database or calling hosted LLMs like Amazon Bedrock, <code>teradatagenai</code> provides the flexibility to align with your organization's security, cost, and performance needs.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "  The <code>TextAnalyticsAI</code> module within the library provides over 11 built-in generative AI functions for powerful in-database NLP capabilities:\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size:16px; font-family:Arial; margin-left:20px; line-height:1.8;\">\n",
    "  <li><code>classify()</code> â€“ Classify text into predefined categories</li>\n",
    "  <li><code>analyze_sentiment()</code> â€“ Perform sentiment analysis</li>\n",
    "  <li><code>detect_language()</code> â€“ Detect the language of a text</li>\n",
    "  <li><code>embeddings()</code> â€“ Generate embeddings for similarity search</li>\n",
    "  <li><code>recognize_entities()</code> â€“ Extract named entities</li>\n",
    "   <li><code>recognize_pii_entities()</code> â€“ Detect and label PII entities</li>\n",
    "  <li><code>extract_key_phrases()</code> â€“ Identify key phrases in text</li>\n",
    "  <li><code>mask_pii()</code> â€“ Mask personally identifiable information (PII)</li>\n",
    "  <li><code>sentence_similarity()</code> â€“ Measure semantic similarity between sentences</li>\n",
    "  <li><code>summarize()</code> â€“ Generate summaries of longer documents</li>\n",
    "  <li><code>translate()</code> â€“ Translate text between languages</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>1. Configure the environment</b></p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "Before we start working with our data, we need to set up our environment. This involves importing the necessary packages and establishing a connection to Vantage.\n",
    "<br>\n",
    "Here's how we can do this: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from teradataml import *\n",
    "from teradatagenai import TextAnalyticsAI, TeradataAI, load_data\n",
    "from IPython.display import display as ipydisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Connect to VantageCloud Lake</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Connect to VantageCloud using `create_context` from the teradataml Python library. Input your connection details, including the host, username, password and Analytic Compute Group name.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking if this environment is ready to connect to VantageCloud Lake...\")\n",
    "\n",
    "if os.path.exists(\"../.config/.env\"):\n",
    "    print(\"Your environment parameter file exist.  Please proceed with this use case.\")\n",
    "    load_dotenv(\"../.config/.env\", override=True)\n",
    "    host = os.getenv(\"host\")\n",
    "    username = os.getenv(\"username\")\n",
    "    my_variable = os.getenv(\"my_variable\")\n",
    "    eng = create_context(host=host, username=username, password=my_variable)\n",
    "    execute_sql('''SET query_band='DEMO=text_analytics_teradatagenai_aws_huggingface.ipynb;' UPDATE FOR SESSION;''')\n",
    "    print(\"Connected to VantageCloud Lake with:\", eng)\n",
    "else:\n",
    "    print(\"Your environment has not been prepared for connecting to VantageCloud Lake.\")\n",
    "    print(\"Please contact the support team.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "\n",
    "<p style=\"font-size:20px; font-family:Arial\"><b>3.Load the data</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "We will be loading sample unstructured data which represents real world advisor-client conversations. We will use this this sample data to explore various NLP tasks including PII masking, entity recognition, summarization, sentiment analysis, language detection and more.\n",
    "</p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "<b>ðŸ’¼ Use Case Summary:</b><br>\n",
    "In the wealth management industry, financial advisors hold many client meetings each week â€” discussing portfolios, insurance, loans, and retirement planning. Manually summarizing and tagging these interactions for compliance, CRM updates, or follow-up actions is time-consuming and often inconsistent.\n",
    "</p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "With Teradataâ€™s teradatagenai library, you can apply generative AI functions directly inside VantageCloud using either hosted LLMs (e.g., via Amazon Bedrock) or Open Source Hugging Face modelsâ€”keeping the data in place for secure, scalable inference.\n",
    "<br>\n",
    "This enables financial firms to:\n",
    "<br>   \n",
    "<ul>\n",
    "    <li>ðŸ“Œ Automate meeting note tagging for faster documentation and regulatory compliance </li>\n",
    "    <li> ðŸ“ˆ Enhance client profiling by identifying frequently discussed financial topics </li>\n",
    "    <li> ðŸ”„ Streamline CRM updates by structuring insights from unstructured text </li>\n",
    "</ul>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from teradataml import DataFrame, copy_to_sql\n",
    "\n",
    "# Define the dataset with embedded fake PII\n",
    "customer_profile = {\n",
    "    \"customer_id\": [101, 102, 103, 104, 105, 106],\n",
    "    \"first_name\": [\"John\", \"Alex\", \"Maria\", \"Sarah\", \"Michael\", \"Claire\"],\n",
    "    \"last_name\": [\"Doe\", \"Kim\", \"Lopez\", \"Lee\", \"Choi\", \"Dupont\"],\n",
    "    \"ssn\": [\"123-45-6789\", \"321-54-9876\", \"231-67-9843\", \"456-89-1230\", \"876-32-1901\", \"654-78-3201\"],\n",
    "    \"address\": [\n",
    "        \"101 Main St, Springfield, IL\",\n",
    "        \"102 Oak Ave, Denver, CO\",\n",
    "        \"103 Pine Rd, Miami, FL\",\n",
    "        \"104 Elm St, Seattle, WA\",\n",
    "        \"105 Maple Ln, Austin, TX\",\n",
    "        \"106 Birch Blvd, Boston, MA\"\n",
    "    ],\n",
    "    \"email\": [\n",
    "        \"john.doe@email.com\",\n",
    "        \"alex.kim@email.com\",\n",
    "        \"maria.lopez@email.com\",\n",
    "        \"sarah.lee@email.com\",\n",
    "        \"michael.choi@email.com\",\n",
    "        \"claire.dupont@email.com\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(customer_profile)\n",
    "\n",
    "# Insert into Teradata (replace if exists)\n",
    "copy_to_sql(df=df, table_name=\"customer_profile\", if_exists=\"replace\")\n",
    "\n",
    "# Create a teradataml DataFrame to validate\n",
    "customer_profile = DataFrame(\"customer_profile\")\n",
    "customer_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advisor_customer_interactions = {\n",
    "    \"customer_id\": [101, 102, 103, 104, 105, 106],\n",
    "    \"advisor_notes\": [\n",
    "    \"John Doe tried to execute a $5,000 ETF purchase of the Fidelity Total Market Index (FTMX) on April 10, but the trade failed due to a pending funding transfer. I explained the delay was caused by a hold on ACH funds. He was confused and I promised to follow up with trade ops. A reattempt was placed for April 11.\",\n",
    "    \"Alex Kim reported a $350 overdraft on his Fidelity Cash Management Account. The issue occurred due to a delayed deposit from his payroll on March 1. I submitted a one-time refund and showed him how to enable low-balance alerts. We also discussed switching his linked credit card (Acct #: 4321-8765-0987-6543) to a no-fee card. He appreciated the quick resolution.\",\n",
    "    \"I had a long session with Maria Lopezfocused on life insurance and estate planning. She's worried about her term policy expiring in 3 years. We reviewed conversion options, whole life, and trust establishment. Maria also updated beneficiaries for her Roth IRA and brokerage. Iâ€™ll send FAQs and a summary for review.\",\n",
    "    \"Sarah Lee applied for a Fidelity credit card but her application was declined for the second time due to a flagged credit report item. She shared frustration about not being informed sooner. I explained the credit criteria and recommended she review her TransUnion report. I also offered to help reapply after 60 days and explore secured credit card options..\",\n",
    "    \"Michael Choi emailed about errors in his student loan refinance . The APR in his dashboard didnâ€™t match his signed agreement. After investigation, I found a backend error had applied a variable rate instead of the fixed 4.25% APR he agreed to. Michael expressed frustration and referenced SoFi as a potential alternative. I apologized and escalated the issue to Loan Ops for immediate correction and promised to track progress. We also discussed auto loan refinancingâ€”Michael currently has a 6.75% APR. I shared that Fidelityâ€™s partner rates start at 4.99% for 36-month terms and 5.49% for 60-month terms, depending on credit. He asked for a link to compare offers and I agreed to follow up with resources.\",\n",
    "    \"Claire Dupont reported her Fidelity Rewards card wasn't providing 2% cashback on travel. I reviewed and saw transactions miscategorized. I submitted a correction and a cashback request. Claire was frustrated and asked about alternative cards. We discussed switching to a travel partner card.\"\n",
    "],\n",
    "    \"customer_question\": [\n",
    "    \"Can you clarify why the ACH hold occurred on account #123456789 and how to prevent this in the future?\",\n",
    "    \"Why did my account (Acct ID: CMA-7789) show a $350 overdraft on March 1, and how can I prevent this going forward?\",\n",
    "    \"Which no-fee credit card did you recommend again for SSN 321-54-9876?\",\n",
    "    \"When should I consider converting to whole life for policyholder Sarah Lee (SSN: 456-89-1230)?\",\n",
    "    \"What were the auto refinance rates you mentioned for Loan ID SL-99881?\",\n",
    "    \"Given my conservative strategy and current market volatility, is now a good time to convert my traditional IRA into a Roth?\"\n",
    "],\n",
    "    \"customer_feedback\": [\n",
    "        \"I appreciate the follow-up, but I'm still confused about the ETF delay.\",\n",
    "        \"The advisor was very helpful and walked me through projections clearly.\",\n",
    "        \"Unhappy with the high feesâ€”need a better explanation and options.\",\n",
    "        \"Disappointed with how long it took to get an answer about my card.\",\n",
    "        \"Grateful for how fast the refund was processed. Thank you\",\n",
    "        \"Good discussion on IRA conversionâ€”still thinking it over.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(advisor_customer_interactions)\n",
    "\n",
    "# Insert into Teradata (replace if exists)\n",
    "copy_to_sql(df=df, table_name=\"advisor_customer_interactions\", if_exists=\"replace\")\n",
    "\n",
    "# Create a teradataml DataFrame to validate\n",
    "advisor_customer_interactions = DataFrame(\"advisor_customer_interactions\")\n",
    "advisor_customer_interactions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<b style='font-size:20px;font-family:Arial'>4.Setting up TeradataAI to access Amazon Bedrock Model</b>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "This section describes how to instantiate the `TeradataAI` class to set up the environment and initialize the LLM endpoint.\n",
    "<br>\n",
    "Users can provide the required authorization information in four different ways:\n",
    "<ol>\n",
    "    <li>Explicitly pass the authorization information to each argument of the function</li>\n",
    "    <li>Set the environment variables related to the authorization arguments</li>\n",
    "    <li>Supply the authorization information via a configuration file</li>\n",
    "    <li>Pass an existing database authorization object containing the credentials using the authorization parameter</li>\n",
    "</ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variables related to the authorization arguments.\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = getpass(prompt='Enter AWS_ACCESS_KEY_ID: ') \n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = getpass(prompt='AWS_SECRET_ACCESS_KEY: ') \n",
    "os.environ['AWS_DEFAULT_REGION'] = getpass(prompt='AWS_DEFAULT_REGION: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the TeradataAI class with the Amazon Bedrock model.\n",
    "llm_aws = TeradataAI(api_type=\"aws\",\n",
    "                     model_name=\"anthropic.claude-v2\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<p style='font-size:20px;font-family:Arial'><b>5. Setting up TextAnalyticsAI to Perform Various Text Analytics Tasks</b></p>\n",
    "<p style='font-size:16px;font-family:Arial'>This section describes how to instantiate the `TextAnalyticsAI` class to access a variety of text analytics methods.\n",
    "</p>\n",
    "### **Key Notes:**\n",
    "\n",
    "- **General Method Arguments:**\n",
    "    - **`column`**:  \n",
    "        Specifies the name of the column to be used.  \n",
    "        - Type: `str`  \n",
    "\n",
    "    - **`data`**:  \n",
    "        Specifies the `teradataml.DataFrame` that includes the column specified by the `column` argument.  \n",
    "        - Type: `teradataml.DataFrame`  \n",
    "\n",
    "- **Optional Parameters:**\n",
    "    - **`persist`**:  \n",
    "        Specifies whether to persist the output in permanent tables.  \n",
    "        - Type: `bool`  \n",
    "        - Default: `False`  \n",
    "\n",
    "    - **`accumulate`**:  \n",
    "        Specifies the name(s) of input `teradataml.DataFrame` column(s) to copy to the output. By default, all input columns are copied to the output.  \n",
    "        - Type: `str` or `list of str`  \n",
    "\n",
    "    - **`volatile`**:  \n",
    "        Specifies whether to store the results in a volatile table.  \n",
    "        - Type: `bool`  \n",
    "        - Default: `False`  \n",
    "\n",
    "- **Additional Arguments (`**kwargs`)**:  \n",
    "    Methods accept additional arguments that can be passed as part of `**kwargs`. For more details, refer to the user guide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the TextAnalyticsAI class with the Amazon Bedrock model.\n",
    "obj = TextAnalyticsAI(llm=llm_aws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>6. Sentiment Analysis</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "In this section, we'll explore the `analyze_sentiment()` function provided by TextAnalyticsAI which classifies text into positive, neutral, or negative categories. Sentiment analysis is:\n",
    "<ul>\n",
    "    <li>A powerful way to understand the voice of the customer\n",
    "    <li>A complex task due to nuanced interpretation, sarcasm, and irony. However, teradatagenai and LLMs provide a quick and powerful way to decrypt customer sentiments</li>\n",
    "</ul></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Using teradatagenai coupled with  like Amazon Bedrock is faster compared to traditional machine learning as there is no need to train machine learning models and related activities such as data labeling, feature engineering, and model tuningâ€”making it easier for teams to get immediate insights.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the sentiment of the reviews in the  customer feedback data.\n",
    "obj.analyze_sentiment(column=\"customer_feedback\",data=advisor_customer_interactions, accumulate=\"customer_feedback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto;\">\n",
    "  <img src=\"./images/sentiment_analysis.png\" alt=\"Sentiment Analysis Chart\" style=\"float: right; margin-left: 20px; width: 550px; border:4px solid #404040; border-radius: 10px; margin-top: 20px;\">\n",
    "\n",
    "  <p style=\"font-size:16px; font-family:Arial;padding-top:20px;\">\n",
    "    Beyond basic classification, sentiment analysis can be extended to support deeper business use casesâ€”for example, tracking product complaints over time by monitoring the frequency and trend of negative sentiment. This helps organizations identify areas for improvement, prioritize feature updates, and enhance customer satisfaction.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>7. Masking Personal Identifiable Information (PII) Entities</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "The `mask_pii()` function is used to mask Personal Identifiable Information (PII) entities within a given text. This can be particularly useful when you want to protect sensitive data in your text.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask PII (Personally Identifiable Information) in the employee data.\n",
    "obj.mask_pii(column=\"customer_question\",data=advisor_customer_interactions,accumulate='advisor_notes',volatile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style='font-size:20px; font-family:Arial;'><b>8. Generating Embeddings</b></p>\n",
    "<p style='font-size:16px; font-family:Arial;'>\n",
    "<div style=\"display: flex; align-items: center; gap: 30px; margin-top: 10px;\">\n",
    "  <div style=\"flex: 1; font-size:16px; font-family:Arial;\">\n",
    "    <p>\n",
    "      The <code>embeddings()</code> function generates vector representations of text from a specified column, capturing the semantic meaning of each entry.\n",
    "    </p>\n",
    "    <p>\n",
    "      These embeddings can then be used for tasks such as semantic similarity, clustering, retrieval, or as input features for downstream machine learning models.\n",
    "    </p>\n",
    "  </div>\n",
    "\n",
    "  <img src=\"./images/clustering.png\" alt=\"Text Embedding Clustering\" style=\"width: 400px; max-width: 100%;border: 4px solid #404040; border-radius: 10px;\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the TeradataAI class with the Amazon Bedrock model.\n",
    "llm_embedding = TeradataAI(api_type=\"aws\",                      \n",
    "               model_name=\"amazon.titan-embed-text-v2:0\",\n",
    "               region=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the TextAnalyticsAI class with the embedding model.\n",
    "obj_embeddings = TextAnalyticsAI(llm=llm_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "obj_embeddings.embeddings(column=\"advisor_notes\",data=advisor_customer_interactions,accumulate=\"customer_id\",output_format='VARCHAR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>9. Entity Recognition </b></p>\n",
    "<p style='font-size:16px; font-family:Arial;'>\n",
    "The <code>recognize_entities()</code> function is designed to identify a wide range of entities within text data. Examples of these entities can include:</p>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style='font-size:16px; font-family:Arial;'>people</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>places</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>products</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>organizations</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>date/time</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>quantities</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>percentages</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>currencies</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>names</td>\n",
    "    </tr>\n",
    "</table>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognize entities in the articles in the data.\n",
    "obj.recognize_entities(column=\"advisor_notes\",data=advisor_customer_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>10. Recognizing Personal Information Identification (PII) Entities</b><p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "The <code>recognize_pii_entities()</code> function provided by TextAnalyticsAI is designed to identify Personal Identifiable Information (PII) entities within text data.  PII entities can include sensitive data like:</p>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style='font-size:16px; font-family:Arial;'>names</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>addresses</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>social security numbers</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>email addresses</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>phone numbers</td>        \n",
    "    </tr>\n",
    "</table>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognize PII entities in the advisor notes.\n",
    "obj.recognize_pii_entities(column=\"advisor_notes\", data=advisor_customer_interactions, accumulate='advisor_notes',volatile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>11. Text Classification </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this section, we'll explore the <code>classify()</code> function provided by TextAnalyticsAI. This function is used to classify the given text.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the advisor notes into multiple relevant financial and emotional categories.\n",
    "obj.classify(\n",
    "    column=\"advisor_notes\",\n",
    "    data=advisor_customer_interactions,\n",
    "    accumulate=\"advisor_notes\",\n",
    "    labels=[\n",
    "        \"Life Insurance\",\n",
    "        \"Estate Planning\",\n",
    "        \"Beneficiary Updates\",\n",
    "        \"Roth IRA\",\n",
    "        \"Student Loan Refinance\",\n",
    "        \"APR Discrepancy\",\n",
    "        \"Auto Loan Refinance\",\n",
    "        \"Credit Card Rewards\",\n",
    "        \"Cashback Dispute\",\n",
    "        \"Card Recommendations\",\n",
    "        \"Retirement Fund Performance\",\n",
    "        \"Investment Strategy\",\n",
    "        \"Portfolio Reallocation\",\n",
    "        \"401(k) Strategy\",\n",
    "        \"Managed Account Fees\",\n",
    "        \"Overdraft Fee\",\n",
    "        \"Account Management\",\n",
    "        \"Fee Waiver\",\n",
    "        \"Customer Complaint\",\n",
    "        \"Customer Escalation\"\n",
    "    ],\n",
    "    multi_label=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>12. Text Summarization</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <code>Summarize()</code> function is used to generate a concise summary of a given text.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the articles in the employee data.\n",
    "obj.summarize(column=\"advisor_notes\",data=advisor_customer_interactions,accumulate='customer_id',volatile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>13. Key Phrase Extraction</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <code>extract_key_phrases()</code> function provided by TextAnalyticsAI is used to extract key phrases from a given text. These key phrases can provide a quick understanding of the main concepts in the text.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract key phrases from advisor notes\n",
    "obj.extract_key_phrases(column=\"advisor_notes\",data=advisor_customer_interactions,volatile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>14.Language Translation </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "The <code>translate()</code> function provided by TextAnalyticsAI is used to translate the language of a given text.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate the text in the employee data to the default language English.\n",
    "obj.translate(column=\"advisor_notes\",data=advisor_customer_interactions,accumulate='advisor_notes',volatile=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>15. Language Detection </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <code>detect_language()</code> function is used to identify the language of a given text.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the language of the quotes in the employee data \n",
    "obj.detect_language(column=\"advisor_notes\",data=advisor_customer_interactions,volatile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>16. Asking the LLM </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <code>ask()</code> function is used to ask questions to the LLM based on the given context.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asking questions to the LLM using context data.\n",
    "# data_partition_column: 'id' and context_partition_column: 'id' are used to partition the data and context tables.\n",
    "# Prompt is used to provide a template for the question and data.\n",
    "obj.ask(column=\"customer_question\", data=advisor_customer_interactions,\n",
    "        context=advisor_customer_interactions, context_column='advisor_notes',\n",
    "        data_partition_column='customer_id', context_partition_column='customer_id',\n",
    "        prompt='''Provide an answer to the customer question using advisor notes as\n",
    "        information relevant to the question.\n",
    "        \\nQuestion: #QUESTION# \\n Data: #DATA#''',\n",
    "        data_position='#DATA#',\n",
    "        question_position='#QUESTION#')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>17.Text Analytics with Open-Source Hugging Face Language Models</b></p>\n",
    "<p style=\"font-size:16px; font-family:Arial\"> As youâ€™ve seen, hosted LLMs like Amazon Bedrockâ€™s Anthropic Claude require no fine-tuning to perform a wide range of NLP tasks. This is because these hosted LLMs are trained on massive, diverse datasets, enabling them to handle tasks such as entity recognition, sentiment analysis, PII masking and more right out of the box.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "While Amazon Bedrock offers the convenience, scalability, and simplicity of hosted models, many organizations also value the greater domain-specific accuracy, data privacy, control, and customization that open-source models provide.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "A <a href=\"https://arxiv.org/pdf/2203.15556\"> recent study from DeepMind </a> shows that smaller, task-specific modelsâ€”when fine-tuned on domain-specific dataâ€”can outperform larger general-purpose models in targeted applications. This makes open-source models an attractive option for organizations wanting greater accuracy, enhanced privacy, and cost-efficiency in specific use cases. However, this approach does require additional expertise and effort to fine-tune and manage these models effectively.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "In the next section, weâ€™ll explore how <code>teradatagenai</code> enables seamless integration with Hugging Face models using BYO-LLM capabilities in VantageCloudâ€”allowing you to deploy compact, specialized models directly where your data lives with GPU acceleration.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>18. Authenticate into User Environment Service (UES) for Container Management</b></p>\n",
    "<p style=\"font-size:16px; font-family:Arial;\">\n",
    "The <code>teradataml</code> library offers simple yet powerful methods for creating and managing custom Python runtime environments within VantageCloud. This gives developers full control over model behavior, performance, and analytic accuracy when running on the Analytic Cluster.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial;\">\n",
    "Custom environments are persistentâ€”created once and reused as needed. They can be saved, updated, or modified at any time, allowing for efficient and flexible environment management.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:18px; font-family:Arial;\"><b>18.1 Container Management Process</b></p>\n",
    "<p style=\"font-size:16px; font-family:Arial;\">\n",
    "\n",
    "<table style=\"width:100%; table-layout:fixed;\">\n",
    "  <tr>\n",
    "    <td style=\"vertical-align:top;\" width=\"40%\">\n",
    "      <ol style=\"font-size:16px; font-family:Arial;\">\n",
    "        <li>Create a unique User Environment based on available base images</li>\n",
    "        <li>Install libraries</li>\n",
    "        <li>Install models and additional user artifacts</li>\n",
    "      </ol>\n",
    "    </td>\n",
    "    <td>\n",
    "      <img src=\"./images/OAF_Env.png\" width=\"600\" alt=\"Container Management Diagram\" style=\"border:4px solid #404040; border-radius: 10px;\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "<p style=\"font-size:18px;font-family:Arial\"><b>18.2 UES Authentication</b></p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">This security mechanism is required to create and manage the Python or R environments that we will be creating.  A VantageCloud Lake user can easily create the authentication objects using the Console in a VantageCloud Lake environment.  For this use case, the authentication objects has already been created and copied into this JupyterLab environment for you.\n",
    "</p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "   \n",
    "<ul style=\"font-size:16px;font-family:Arial; margin-top:4px;\">\n",
    "  <li><a href=\"https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Teradata-Package-for-Python-on-VantageCloud-Lake/Working-with-Open-Analytics/APIs-to-Use-with-Open-Analytics-Framework/API-to-Set-Authentication-Token/set_auth_token\">Click here</a> to see more details about using the Teradata APIs to set the authentication objects.</li>\n",
    "\n",
    "  <li>Check out <a href=\"https://medium.com/teradata/deploy-hugging-face-llms-on-teradata-vantagecloud-lake-with-nvidia-gpu-acceleration-d94d999edaa5\">Step 4</a> of this tutorial to to see more details about configuring a VantageCloud Lake Environment to use our Open Analytics Framework</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the values for the Open Analytics Endpoint, the Access Token and the location of the .pem file.\n",
    "# We also assign the name of our GPU Compute Group.\n",
    "\n",
    "open_analytics_endpoint = os.getenv(\"ues_uri\")\n",
    "access_token = os.getenv(\"access_token\")\n",
    "pem_file = os.getenv(\"pem_file\")\n",
    "gpu_compute_group = os.getenv(\"gpu_compute_group\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure.ues_url = open_analytics_endpoint\n",
    "if set_auth_token(ues_url=open_analytics_endpoint, username=username, pat_token=access_token, pem_file=pem_file):\n",
    "    print(\"UES Authentication successful\")\n",
    "else:\n",
    "    print(\"UES Authentication failed. Check credentials.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if I have any existing environments\n",
    "env_list = list_user_envs()\n",
    "print(\"Available Environments:\")\n",
    "ipydisplay(env_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">  \n",
    "TeradataAI handles the download and installation of the Hugging Face model (example: <i>'tner/roberta-large-ontonotes5</i>) in the user's environment. If an environment name is not specified, a default name <i>'td_gen_ai_env'</i> will be used. The TeradataAI class will manage the entire creation and setup process. In the background, this process utilizes Teradataâ€™s <code>Bring Your Own Large Language Model (BYO LLM)</code> offering.</p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">For this use case, we're going to check if the OAF Container already exist.  If it doesn't, we will create it to show the process of using the <code>tner/roberta-large-ontonotes5</code> model with the <code>teradatagenai</code> package. </p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">  \n",
    "Define the Hugging Face model and initialize the TeradataAI Class </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Accessing the LLM endpoint and initializing TeradataAI and TextAnalyticsAI\n",
    "model_name = 'tner/roberta-large-ontonotes5'\n",
    "model_args = {'transformer_class': 'AutoModelForTokenClassification',\n",
    "              'task' : 'token-classification'}\n",
    "llm = TeradataAI(api_type = \"hugging_face\",\n",
    "                 model_name = model_name,\n",
    "                 model_args = model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">This is creating a new OAF Container and then installing 40+ libraries.  After those are installed, it will begin downloading and installing the model.  If your Kernel status is showing <b>Idle</b>, please wait until you see that the \"Completed\" message directly above this cell. This could take several minutes.</p>\n",
    "\n",
    "<p style=\"font-size:18px;font-family:Arial\"><b>18.3 Create the TextAnalyticsAI object</b></p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">Now we can execute the portion of the process that will run in our GPU Analytics Cluster.  We configure the TextAnalyticsAI object with the preferred large language model. This will enable us to execute a variety of text analytics tasks.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = TextAnalyticsAI(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql(f\"SET SESSION COMPUTE GROUP {gpu_compute_group};\")\n",
    "print(f\"Compute group set to {gpu_compute_group}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj.recognize_entities(column='advisor_notes', data=advisor_customer_interactions, delimiter=\"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>19. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>19.1 Delete your OAF Container</b></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the existing user environment \n",
    "try:\n",
    "    result = remove_env(\"td_gen_ai_env\")\n",
    "    print(\"Environment removed!\")\n",
    "except Exception as e:\n",
    "    print(\"Could not remove the environment!\")\n",
    "    print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>19.2 Remove your database Context</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = remove_context()\n",
    "    print(\"Context removed!\")\n",
    "except Exception as e:\n",
    "    print(\"Could not remove the Context!\")\n",
    "    print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>View the full TeradataAI Help</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(TeradataAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analyticsâ„¢</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright Â© Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
